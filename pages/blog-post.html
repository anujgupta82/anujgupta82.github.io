<!doctype html>
<html lang="en" class="no-js">

<head>
    <meta charset="utf-8">
    <!-- begin SEO -->
    <title>Anuj-Gupta</title>
    <meta property="og:locale" content="en-US">
    <meta property="og:site_name" content="Your Name / Site Title">
    <meta property="og:title"
        content="academicpages is a ready-to-fork GitHub Pages template for academic personal websites">
    <meta name="description" content="About me">
    <meta property="og:description" content="About me">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/ld+json">
            {
                "@context": "http://schema.org",
                "@type": "Person",
                "name": "Your Name",
                
                "sameAs": null
            }</script>
    <!-- end SEO -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-DELSE55VHS"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-DELSE55VHS');
    </script>
    <link href="" type="application/atom+xml" rel="alternate" title="Your Name / Site Title Feed">
    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script>
        document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script>
    <!-- For all browsers -->
    <link rel="stylesheet" href="/assests/main.css">
    <meta http-equiv="cleartype" content="on">

    <link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
    <meta name="msapplication-TileColor" content="#000000">
    <!-- <meta name="msapplication-TileImage"
        content="https://academicpages.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
    <meta name="msapplication-config" content="/images/browserconfig.xml"> -->
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="/assests/academic.css" />
    <script type="text/x-mathjax-config">
             MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); 
        </script>
    <script type="text/x-mathjax-config">
             MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); 
        </script>
    <!-- <script src='/data/main.js'></script> -->
    <script src="https://kit.fontawesome.com/860247de27.js" crossorigin="anonymous"></script>
    <!-- end custom head snippets -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DELSE55VHS"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-DELSE55VHS');
</script>

<body>
    <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->
    <div class="masthead">
        <div class="masthead__inner-wrap">
            <div class="masthead__menu">
                <nav id="site-nav" class="greedy-nav">
                    <button>
                        <div class="navicon"></div>
                    </button>
                    <ul class="visible-links">
                        <li class="masthead__menu-item masthead__menu-item--lg">
                            <a href="/index.html">ANUJ GUPTA</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="/pages/book.html"">BOOK</a>
                        </li>
                        <li class=" masthead__menu-item">
                                <a href="/pages/blog-post.html">BLOG POSTS</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="/pages/talk.html">TALKS</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="/pages/workshop.html">WORKSHOP</a>
                        </li>
                        <li class="masthead__menu-item">
                            <a href="/pages/publication.html">PUBLICATIONS</a>
                        </li>

                    </ul>
                    <ul class="hidden-links hidden"></ul>
                </nav>
            </div>
        </div>
    </div>
    <div id="main" role="main">
        <div class="sidebar sticky">
            <div itemscope itemtype="http://schema.org/Person">
                <div class="author__avatar">
                    <img src="/images/anuj_gupta_pro.jpg" class="author__avatar" alt="Your Sidebar Name">
                </div>
                <div class="author__content">
                    <h3 class="author__name">Anuj Gupta</h3>
                    <p class="author__bio">Executive Advisor on <b>AI</b> <b>|</b> Fractional Head of <b>AI</b> <b>|</b>
                        Helping Businesses unlock
                        the full potential of <b>AI</b> <b>|</b> Coaching leadership teams on AI <b>|</b> Author of
                        major book in AI
                        <b>(O’Reilly)</b> <b>|</b> Angel Investor <b>|</b> Board Member
                    </p>
                </div>
                <div class="author__urls-wrapper">
                    <button class="btn btn--inverse">Follow</button>
                    <ul class="author__urls social-icons">
                        <!-- <li>
                                <i class="fa fa-fw fa-map-marker" aria-hidden="true"></i>
                                Location
                            </li> -->
                        <li>
                            <a href="https://www.linkedin.com/in/anujgupta-82/">
                                <i class="fa-brands fa-linkedin"></i>
                                LinkedIn
                            </a>
                        </li>
                        <li>
                            <a href="https://twitter.com/anujgupta82">
                                <i class="fa fa-twitter" aria-hidden="true"></i>
                                Twitter
                            </a>
                        </li>
                        <li>
                            <a href="https://gradient-advisors.ai/">
                                <i class="fa-solid fa-globe" aria-hidden="true"></i> Gradient Advisors
                            </a>
                        </li>

                    </ul>
                </div>
            </div>
        </div>
        <div class="archive">
            <h1 class="page__title">Blog posts</h1>
            <h2 id="2199" class="archive__subtitle">2023</h2>
            <div class="list__item">

                <div class="blog-post-card small" onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline">
                            <a>Product management for AI products - old wine in new bottle?</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2199-01-01T00:00:00-08:00">Aug 05, 2023</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <p>

                        <div class="archive__item-excerpt">
                            <!-- <h1>Lessons from Recent Layoffs in AI</h1> -->
                            <p>

                                <a href="https://www.entrepreneur.com/business-news/netflix-offers-up-to-900k-for-ai-focused-product-manager/456613"
                                    target="_blank">
                                    <strong> Netflix recently posted a job opening for an AI Product Manager role with a
                                        staggering annual salary of up to $900,000.</strong>
                                </a>
                                The question arises: why such a high
                                compensation for an AI PM? When was the last time a Product Manager got paid so high?

                            </p>
                            <p class="center two-thirds">
                                <a href="/images/netflix.png">
                                    <img src="/images/netflix.png" style="display: block; margin: 0 auto;">
                                </a>
                            </p>

                            </p>

                            </p>
                            <p>The answer lies in the specialized skill set required for product management in the realm
                                of
                                AI. The traditional principles and experiences in product management for standard
                                software
                                products do not suffice for AI products. Product management in AI development demands a
                                significant upgrade.
                            </p>
                            <p>

                                Before delving into the specifics of 'what' product management skills to enhance and
                                'how'
                                to upgrade them to thrive in the AI product era, it's crucial to address the 'why.' Why
                                do
                                traditional product management methodologies and approaches fall short in the AI-first
                                world? Let's explore the fundamental changes from traditional software to AI software
                                that
                                necessitate the evolution of product management skills:
                            </p>


                            <div class="archive__item-excerpt">
                                <!-- <h2>Key Lessons:</h2> -->
                                <ol>
                                    <!-- add numbering in it -->
                                    <li>
                                        <p><strong>Stochastic vs Deterministic:</strong> Traditional software (referred
                                            to
                                            as software
                                            1.0)
                                            operates deterministically, meaning it consistently produces the same output
                                            for
                                            a
                                            given system and input. In contrast, AI software (referred to as software
                                            2.0)
                                            is
                                            stochastic, meaning it can yield varying outputs for the same system and
                                            input.
                                        </p>
                                        <p> As a product manager, meticulous control over the user experience is
                                            paramount,
                                            especially to prevent negative user experiences. In the realm of software
                                            1.0,
                                            this
                                            entails thorough scenario planning within the Product Requirements Document
                                            (PRD) to
                                            anticipate and design for potential errors. Once the software undergoes
                                            comprehensive testing, scenarios that pass ensure a reliable user experience
                                            in
                                            production, barring any unforeseen bugs.</p>

                                        <p>However, the landscape shifts with AI software (software 2.0). Even after
                                            rigorous
                                            testing, AI systems may still generate incorrect responses due to their
                                            stochastic
                                            nature. Such occurrences are not considered bugs but rather inherent to the
                                            probabilistic framework of AI software. Acknowledging that no AI system
                                            achieves
                                            perfect accuracy, product managers must proactively devise user experiences
                                            capable
                                            of managing errors and gracefully handling failures. This necessitates a
                                            specialized
                                            understanding of AI design processes for product managers to effectively
                                            navigate
                                            this terrain.</p>

                                    </li>
                                    <li>
                                        <p><strong>Designing for loops (control loop, feedback loop,
                                                human-in-the-loop):</strong> Given the
                                            stochastic nature of AI systems, errors are inevitable. As a product
                                            manager,
                                            it's
                                            imperative to establish control loops to swiftly determine whether the AI's
                                            output
                                            is beneficial to the end user. If not, end users should be empowered to take
                                            control
                                            of the system to override the AI's decisions, stop AI recommendations.</p>

                                        <p> Similarly, the product team must institute feedback loops for each AI
                                            feature to
                                            assess its efficacy for end users. This involves gathering data across
                                            various
                                            scenarios to ascertain when the feature performs optimally and when it
                                            falters.
                                        </p>

                                        <p> Additionally, designing for humans-in-the-loop is crucial, enabling the
                                            seamless
                                            transition of control from AI systems to human operators when necessary.</p>
                                    </li>
                                    <li>
                                        <p><strong>Data Collection: </strong>It's widely recognized that AI relies
                                            heavily
                                            on data. However,
                                            the
                                            responsibility of data collection doesn't fall on AI scientists; rather, it
                                            lies
                                            with the product team. Why? Because the product team holds ownership of the
                                            product,
                                            making them best suited to embed the necessary instrumentation for data
                                            collection.</p>

                                        <p>This is where PMs need to understand the lingo of data systems and work with
                                            data
                                            engineering teams to create roadmaps & sprints for data collection. In large
                                            AI
                                            first MNCs, this is a very specialized role called Data PM.</p>
                                    </li>
                                    <li><strong>Introducing Users to AI:</strong> When integrating AI into your products
                                        for
                                        the first time,
                                        it's vital to introduce AI to your users delicately. Setting the right
                                        expectations
                                        and assuring users that they can regain control if they're uncomfortable is
                                        essential. Achieving this demands the creation of a highly specialized flows &
                                        UX.
                                    </li>
                                    <li>
                                        <p><strong>Economics of AI:</strong> AI constitutes a costly endeavor,
                                            encompassing
                                            expenses in data
                                            acquisition, cleaning, storage to create datasets; computational resources,
                                            and
                                            talent acquisition. Given the high costs involved, not every potential use
                                            case
                                            justifies the investment. Hence, it's imperative to select use cases
                                            judiciously.
                                        </p>
                                        <p> Within a company, the business team comprehends business dynamics but often
                                            lacks
                                            technical expertise, while individual contributors (ICs) in the AI team
                                            possess
                                            technical proficiency but may not grasp business intricacies. In this
                                            landscape,
                                            product managers play a pivotal role, bridging the gap between technology,
                                            user
                                            needs, and business objectives. Consequently, the responsibility of
                                            evaluating
                                            and
                                            determining the feasibility & viability of AI use cases predominantly falls
                                            on
                                            the
                                            shoulders of product managers.</p>


                                    </li>
                                    <li><strong>The AI development process is very different:</strong> The transition
                                        from
                                        traditional
                                        software development (Software 1.0) to AI-driven systems (Software 2.0)
                                        introduces
                                        significant differences in how product management approaches roadmaps and
                                        timelines.
                                        Here are some implications for product owners:


                                        <ul class="alphabet-list">
                                            <li><strong>Uncertainty in Improvement:</strong> Unlike traditional software
                                                where incremental
                                                improvements are often achievable by addressing specific issues or
                                                corner
                                                cases, AI-driven systems may hit performance plateaus where further
                                                improvements are challenging. This uncertainty must be factored into
                                                product
                                                roadmaps and timelines, as achieving desired performance levels may
                                                require
                                                more extensive reevaluation and experimentation.
                                            </li>
                                            <li>
                                                <strong>Extended Development Cycles:</strong> Improving AI-driven
                                                systems
                                                often involves
                                                revisiting the underlying algorithms, data pipelines, or model
                                                architectures, which can be time-consuming processes. Product owners
                                                need to
                                                allocate sufficient time in their roadmaps for research,
                                                experimentation,
                                                and validation of new approaches, potentially extending development
                                                cycles
                                                beyond what is typical for traditional software updates.
                                            </li>
                                            <li><strong>Resource Allocation:</strong> Given the longer development
                                                cycles
                                                associated with
                                                improving AI systems, product owners may need to allocate additional
                                                resources, both in terms of engineering talent and computational
                                                resources.
                                                This may require reprioritizing other initiatives or increasing
                                                investment
                                                in AI research and development to meet performance targets within the
                                                desired timeframe.

                                            </li>
                                        </ul>
                                    </li>
                                </ol>
                            </div>


                        </div>
                    </article>
                </div>

            </div>
            <h2 id="2199" class="archive__subtitle">2022</h2>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline">
                            <a>Alexa AI and Layoffs</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2199-01-01T00:00:00-08:00">Nov 23, 2022</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <p>
                        <div class="archive__item-excerpt">
                            <h1>Lessons from Recent Layoffs in AI</h1>
                            <p>Yesterday I was reading an article on recent layoffs at Alexa voice assistant unit in
                                Amazon.
                                This got me thinking. I believe the whole episode contains some critical lessons for
                                many AI
                                teams:</p>
                            <div class="archive__item-excerpt">
                                <h2>Key Lessons:</h2>
                                <ul>
                                    <li>You can have the most cutting-edge technology which even your competition tries
                                        to
                                        copy, yet if it doesn’t move business needles it is a liability.</li>
                                    <li>Business & Product took a leap of faith that users will order goods purely using
                                        voice without even looking at items even once. This and other monetization
                                        efforts
                                        didn’t happen and everything fell apart.</li>
                                    <li>Mistakes made by the product team are super expensive. PMs must find ways to
                                        list
                                        down and validate assumptions, especially leap of faith, as quickly as possible.
                                        In
                                        the case of Alexa, I wonder if there were ways to test these without having to
                                        invest so much time & effort.</li>
                                    <li>Alexa single-handedly contributed to so many developments in speech tech, it is
                                        an
                                        absolute marvel. Yet reduced only to alarms, how is the weather outside and play
                                        song. Primarily due to points (2) and (3).</li>
                                    <li>Business needs to understand that building cutting-edge tech takes time - no
                                        matter
                                        how much you may push, it can't be done in days, weeks or sometimes even months.
                                    </li>
                                </ul>
                            </div>
                            <div class="hashtags">
                                <p>#Learnings_From_AI_Trenches #business #technology #ai #BuisnessOfAI #ai
                                    #machinelearning
                                    #nlp #nlproc #tech #deeplearning #PayItForward #MachineLearning #AI #nlproc
                                    #naturallanguageprocess #speechrecoganition</p>
                            </div>
                        </div>
                    </article>
                </div>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Moonlighting & Side Hustle - Problem and Solution</a>
                        </h2>
                        <!-- <h2 class="archive__item-title" itemprop="headline">
                            <a href="" rel="permalink">Product management for AI products - old wine in new bottle?</a>
                        </h2> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2199-01-01T00:00:00-08:00">Oct 20, 2022</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <p>
                        <div class="archive__item-excerpt">
                            <p>Moonlighting in tech has emerged as major stress for companies. Below is my personal take
                                on
                                it:
                                <br>
                                The core reason IMO is: companies/consultants project every job as very high-end work
                                (once-in-a-lifetime opportunity) but often the reality is very different. Being a
                                knowledge
                                industry, tech leaders talk about hunting as lion (hunt, rest, repeat) but in reality do
                                nothing to facilitate it and make you work like a cow (graze all day). All this along
                                with
                                ‘fairness’ in compensation + hire-fire policy means there is nothing left nothing on
                                employee loyalty. Now that employees are giving back to employers a dose of their own
                                medicine (no show on day of joining, quick churn) - there is hue n cry! IMO the blame
                                lies
                                equally on both sides.
                                <br><br>
                                Possible Solution? Both employees and employers must understand, professional
                                relationship
                                is a 2 way street. Both will have to do their part to solve it:
                            </p>
                            <div class="archive__item-excerpt">
                                <ul>
                                    <li>Organizations must clearly specify minimum working hours they expect. Be explit,
                                        say
                                        Mon-Fri (10am-7pm) or watever works for them. Be reasonable - dont say 24 hrs a
                                        day,
                                        7 days a week!</li>
                                    <li>In their free time, employees should be free to pursue their interests - some
                                        like
                                        to chill n watch Netflix, others like to work on side gigs. That should be
                                        entirely
                                        employee’s choice - no organizations should not dictate this</li>
                                    <li>Organizations should make moonlighting policy super transparent. Create a system
                                        where employees must inform of all side gigs to the employer. In return,
                                        employers
                                        must not object to side gigs unless there is a clear conflict of interest.</li>
                                    <li>Organizations should evaluate employees purely on their performance in their
                                        organization. If the performance is great, reward them accordingly. If not, put
                                        them
                                        on PIP or let them go. Unless a side gig is clearly impacting an employee’s
                                        performance - it should not concern the employer.</li>
                                    <li>Employees must understand companies will be more transparent only if employees
                                        don’t
                                        cheat. So:
                                        <!-- add the more list -->
                                        <ul>
                                            <li>Only 1 full-time employment. Can’t take 2 overlapping jobs. To be more
                                                precise - time commitment of one job must not conflict with time
                                                commitment
                                                of any other gig.</li>
                                            <li>Employee can have side gigs but only in your free time (time not
                                                commited to
                                                organization).</li>
                                            <li>Employee must inform of all side gigs to employer.</li>
                                            <li>Employers must not object to side gigs unless there is a clear conflict
                                                of
                                                interest.</li>
                                            <li>Employees’s side gig cannot be with competitor companies for up to 1 yrs
                                                (maybe even 2 years) after leaving any employer. Organizations must have
                                                a
                                                strong right to protect IP, business strategy, internal details etc. Any
                                                clear conflict of interest must be strictly prohibited.</li>
                                        </ul>
                                    </li>
                                    <li>Despite all this, if an employee moonlighting, Organizations should have the
                                        legal
                                        right to take a very strict action and penalize them heavily.</li>
                                </ul>
                            </div>
                            <div class="">
                                <p>A bunch of companies such as Swiggy have created such policies. 100% transparency on
                                    both
                                    sides is the only way forward to create a true knowledge economy. IMO the way to
                                    attract
                                    really smart people in a knowledge economy is flexibility, challenging work and
                                    transparency.</p>
                            </div>
                        </div>
                    </article>
                </div>
            </div>

            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Pay It Forward</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">July 11, 2022</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>I am often asked why is AI is a hard technology? (both in terms of time and money). There
                                are
                                multiple reasons for it:</p>
                            <div class="archive__item-excerpt">

                                <ul>
                                    <li>
                                        <p>Finding the right use case: finding a problem that is important to its users
                                            and
                                            can be solved well by AI. I talked earlier on this <a
                                                href="https://lnkd.in/eiAYU9eq">here</a></p>
                                    </li>
                                    <li>Having the right data: most companies have tonnes of data but seldom have the
                                        data
                                        for the problem at hand. In AI its not just the quantity of data that matters
                                        but
                                        also the quality of data. Do you have the training data that resembles the
                                        production data very closely? Does it have enough data points that represent
                                        various
                                        outliers, mean data points, data points near the actual decision boundary etc
                                    </li>
                                    <li>
                                        Labeling cost - If you need to get your data manually labeled, this will need
                                        lots
                                        of time and money. The process of labeling itself might not be straightforward.
                                        How
                                        do you benchmark the quality of labeling? If your labelers are making mistakes
                                        this
                                        can jeopardize the entire project.
                                    </li>
                                    <li>
                                        Compute cost - the cost of the compute needed for training the model and for
                                        inference. This is especially crucial if your solution uses deep learning.
                                    </li>
                                    <li>
                                        Going from a solution to the solution: In AI there is no one way to solve a
                                        problem.
                                        There are multiple ways and each will give you a different accuracy. Getting
                                        from
                                        the point where you have a model that gives you an acceptable performance to
                                        getting
                                        to a model that gives you fabulous performance is often a very long journey.
                                    </li>
                                    <li>
                                        Fitting model into the product to get AI-driven feature: Its not just a simple
                                        API
                                        integration. One needs to figure out the best UX to serve the predictions,
                                        should
                                        this UX be intrusive or soft suggestions, UX should be able to gracefully handle
                                        the
                                        scenarios when the model makes mistakes, a mechanism to let the human take over
                                        when
                                        it is going all wrong for the end-user, instrumentation to collect data to
                                        continuously evaluate the performance of the model on prod data, instrumentation
                                        to
                                        collect data for future modeling efforts.
                                    </li>
                                    <li>
                                        Need to retrain model: many times AI systems require one to retrain the model
                                        after
                                        every 15-30 days on the latest data.


                                    </li>
                                    <li>
                                        Talent: DS/ML team alone cannot pull off all the above. You need good and
                                        diverse
                                        talent for this - ML/DS folks who can evaluate the various approaches depending
                                        on
                                        the situation and can take the most suitable one to build the right model (and
                                        not
                                        blindly apply DL), Data engineers to build data pipelines to collect all data, a
                                        product manager who can figure out right use case, build instrumentation, UX to
                                        handle mistakes, a AI leader who understands this entire life cycle and work
                                        very
                                        closely with business and speak their language. This talent doesn’t come cheap.
                                    </li>
                                </ul>
                            </div>

                            <div class="archive__item-excerpt">
                                For AI effort to fail - going wrong on just one of the above is enough.

                            </div>
                        </div>
                    </article>
                </div>

            </div>

            <h2 id="2015" class="archive__subtitle">2021</h2>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Innovation in AI Teams</a>
                        </h2>

                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2015-08-14T00:00:00-07:00">Oct 22, 2021</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">

                        <div class="archive__item-excerpt">

                            <p>Innovation and AI are two words that often go hand in hand. However, depending on the
                                type of
                                setting an AI team is embedded in - the semantics on ‘Innovation’ can vary.
                                <br>

                                If you are part of the research lab, this often means AI team works on fundamental
                                problems
                                and create fundamental & new techniques to power cutting-edge solutions. They publish a
                                lot,
                                advance the entire area in a fundamental way - this is their true north star. It goes
                                without saying this means lot of publications, paper presentation, talks & tutorials at
                                research conferences, very close collaboration with academia etc.
                                <br>
                                When it comes to AI teams working in the product settings, the innovation here is of
                                very
                                different type. And in this post and next I will try n focus on this facet. There are
                                mainly
                                4 type of innovations that happen in such teams:
                            </p>

                            <div class="archive__item-excerpt">

                                <ul>
                                    <li><strong>Finding newer uses cases and touch points in your product(s) where AI
                                            can
                                            deliver a completely new experience to the user</strong> : This innovation
                                        often
                                        create USP/key
                                        differentiator for the product compared to the competition in the respective
                                        segment. And if the feature is killer, it changes the user’s behavior which in
                                        turn
                                        changes user expectation. And then the competition has no other option but to
                                        play
                                        the catch-up game. This creates a very strong moat. For example, YouTube uses AI
                                        to
                                        generate subtitles in multiple languages on the fly. They have fundamentally
                                        changed
                                        user expectations and other platforms have to have a similar feature.
                                        <p>This kind of innovation is often not as easy as it may sound. I have written
                                            about this in an earlier post (ref : <a
                                                href="https://www.linkedin.com/posts/activity-6830708981107867648-JQz_/">Hobbiton
                                                - Uses cases where AI can deliver great returns</a>). This requires
                                            first
                                            principle thinking. Product managers who can envision features in a
                                            completely
                                            new way using AI, very close collaboration between AI &amp; product teams to
                                            understand what is possible what is not, a very good execution to deliver
                                            A-class experience (despite AI model will make mistakes).</p>

                                    </li>
                                    <li>
                                        <strong>Building the dataset for the problem at hand</strong> : For AI teams
                                        embedded in product settings, building a comprehensive dataset for the problem
                                        at hand is often 80% of the battle. Building such a dataset is never writing a
                                        bunch of queries on a massive data store at your disposal. AI Teams often have
                                        to come up with very smart strategies, hacks to augment data to arrive at a
                                        comprehensive dataset. Also, this is not a one-time activity but often highly
                                        iterative. What more type of data is needed - comes from the kind of mistakes
                                        your models are making.
                                        <p>I will soon be writing a dedicated post on some of the best examples I have
                                            seen/heard on innovative ideas to collect data.</p>

                                    </li>
                                    <li>
                                        <strong>Publishing paper/patent (doesn’t happen that often)</strong> : AI
                                        teams embedded in product teams do write patents and papers - but this is seldom
                                        their true north star.</p>
                                    </li>


                                </ul>
                            </div>

                            <div class="">
                                <p>
                                <p>So what about coming up with newer techniques? Rarely AI teams embedded in product
                                    teams
                                    do this. Why? Because in most cases, known techniques with a comprehensive dataset
                                    with
                                    rigorous evaluation itself can take your AI solution very very far on business
                                    metrics.
                                    From there on it is mostly a game of diminishing returns. Read about “later part of
                                    S
                                    curve” in my earlier post on “[ROI in AI]
                                    (https://www.linkedin.com/posts/activity-6842736295173775360-etDf/)”. This is not
                                    true
                                    only if AI is the backbone of your product and your core value proposition.</p>
                                </p>
                                <p>To read more on AI in industry vs Acedemia, please read my earlier post “[Why machine
                                    learning in the industry is different from that is academia]
                                    (https://www.linkedin.com/posts/activity-6836567604467970048-nQu8/)”
                                    <br>
                                    #Learnings_From_AI_Trenches
                                </p>
                            </div>
                            </p>
                        </div>
                    </article>
                </div>

            </div>
            <!-- <h2 id="2014" class="archive__subtitle">2014</h2> -->
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>ROI in AI - Expectations vs Reality</a>
                        </h2>

                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2014-08-14T00:00:00-07:00">Oct 3, 2021</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>A lot of companies and teams are betting big on DeepTech like AI to drive the next phase
                                of
                                growth. While AI can certainly be the “energy” to help you move to the next orbit, most
                                teams falter big time. While there are many reasons for this, one key reason is the
                                ill-founded expectations by senior people (VPs, CXOs, business leaders etc) in the
                                company.
                                Today’s post will explore this facet of AI - often the least spoken one.</p>

                            <br>

                            <p>Most leaders/companies start AI in their teams/product lines much later. Traditional
                                corporate wisdom has always advocated “quick” wins because that is how one establishes
                                themselves and gets the key stakeholders super excited. So they advocate the same in AI!
                            </p>

                            <p>This is also driven by:</p>

                            <div class="archive__item-excerpt">

                                <ul>
                                    <li>Articles on AI in popular media with lofty claims (remember the humanoid dancing
                                        in
                                        Tesla AI day or Sophia - not many people understand these are mere marketing and
                                        perception gimmicks)</li>
                                    <li>The thought that AI at the end of the day is a code - so it cannot be very
                                        different
                                        from software engineering. The issues are mere initial hiccups which is always
                                        the
                                        case with any new tech, so is the case with AI</li>

                                </ul>
                            </div>

                            <div class="archive__item-excerpt">
                                <p>So most leaders expect the ROI curve in AI to be a vertical takeoff. This expectation
                                    is
                                    further fueled by the fact that AI doesn’t come cheap - data, data engg &amp; AI
                                    teams,
                                    talent cost, hardware cost, data collection &amp; labeling cost and time etc, MLOps
                                    etc
                                    Read my previous write up titled <a href="https://lnkd.in/eCqRgq7v">the economics of
                                        AI</a></p>

                                <p>This is where most Orgs/Teams make THE mistake. The true ROI curve in AI is very very
                                    different from their expectations. As shown in the figure below, it follows a S
                                    shape
                                    curve.</p>

                            </div>
                            <p class="center two-thirds"><a href="/images/ROI_blog.jpeg"><img
                                        src="/images/ROI_blog.jpeg"></a></p>

                            </p>
                            <div class=" archive__item-excerpt">
                                <ul>
                                    <li>
                                        Initial lower part of S: One needs to invest a lot of time and energy with very
                                        little ROI - finding <a href="https://lnkd.in/e6-ikYb9">the right use case</a>,
                                        right quality and quantity of data and labels (more on this in another post),
                                        right
                                        modeling approach, right metrics etc. This can take anywhere between 1-3 years.
                                    </li>
                                    <li>
                                        Middle part of S: This is where one gets the highest ROI per unit effort. This
                                        is
                                        because most of the hard work has been done in the first 1-3 years. All key
                                        stakeholders have a better understanding of the AI journey. This phase is all
                                        about
                                        building the 2nd/3rd version of AI systems
                                    </li>
                                    <li>
                                        Later upper part of S: This is where the ROI again starts to stagnate. This
                                        phase is
                                        where your team is building the 6th/7th version of the system and trying to push
                                        systems performance to the upper 90s. This often requires completely new
                                        approaches,
                                        new algorithms. Its not just adding a couple of lines of code!
                                    </li>
                                </ul>

                            </div>
                            <p>Another thing most folks don’t necessarily understand is that each of the 3 different
                                phases
                                of the curve requires a very different strategy - type of goals, kind of skillsets,
                                focus
                                areas, etc</p>
                        </div>
                    </article>
                </div>

            </div>
            <!-- <h2 id="2013" class="archive__subtitle">2013</h2> -->
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Making AI Work For You</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Sep 18, 2021</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>I am often asked why is AI is a hard technology? (both in terms of time and money). There
                                are
                                multiple reasons for it:</p>
                            <div class="archive__item-excerpt">

                                <ul>
                                    <li>
                                        <p>Finding the right use case: finding a problem that is important to its users
                                            and
                                            can be solved well by AI. I talked earlier on this <a
                                                href="https://lnkd.in/eiAYU9eq">here</a></p>
                                    </li>
                                    <li>Having the right data: most companies have tonnes of data but seldom have the
                                        data
                                        for the problem at hand. In AI its not just the quantity of data that matters
                                        but
                                        also the quality of data. Do you have the training data that resembles the
                                        production data very closely? Does it have enough data points that represent
                                        various
                                        outliers, mean data points, data points near the actual decision boundary etc
                                    </li>
                                    <li>
                                        Labeling cost - If you need to get your data manually labeled, this will need
                                        lots
                                        of time and money. The process of labeling itself might not be straightforward.
                                        How
                                        do you benchmark the quality of labeling? If your labelers are making mistakes
                                        this
                                        can jeopardize the entire project.
                                    </li>
                                    <li>
                                        Compute cost - the cost of the compute needed for training the model and for
                                        inference. This is especially crucial if your solution uses deep learning.
                                    </li>
                                    <li>
                                        Going from a solution to the solution: In AI there is no one way to solve a
                                        problem.
                                        There are multiple ways and each will give you a different accuracy. Getting
                                        from
                                        the point where you have a model that gives you an acceptable performance to
                                        getting
                                        to a model that gives you fabulous performance is often a very long journey.
                                    </li>
                                    <li>
                                        Fitting model into the product to get AI-driven feature: Its not just a simple
                                        API
                                        integration. One needs to figure out the best UX to serve the predictions,
                                        should
                                        this UX be intrusive or soft suggestions, UX should be able to gracefully handle
                                        the
                                        scenarios when the model makes mistakes, a mechanism to let the human take over
                                        when
                                        it is going all wrong for the end-user, instrumentation to collect data to
                                        continuously evaluate the performance of the model on prod data, instrumentation
                                        to
                                        collect data for future modeling efforts.
                                    </li>
                                    <li>
                                        Need to retrain model: many times AI systems require one to retrain the model
                                        after
                                        every 15-30 days on the latest data.


                                    </li>
                                    <li>
                                        Talent: DS/ML team alone cannot pull off all the above. You need good and
                                        diverse
                                        talent for this - ML/DS folks who can evaluate the various approaches depending
                                        on
                                        the situation and can take the most suitable one to build the right model (and
                                        not
                                        blindly apply DL), Data engineers to build data pipelines to collect all data, a
                                        product manager who can figure out right use case, build instrumentation, UX to
                                        handle mistakes, a AI leader who understands this entire life cycle and work
                                        very
                                        closely with business and speak their language. This talent doesn’t come cheap.
                                    </li>
                                </ul>
                            </div>

                            <div class="archive__item-excerpt">
                                For AI effort to fail - going wrong on just one of the above is enough.

                            </div>
                        </div>
                    </article>
                </div>

            </div>
            <!-- <h2 id="2012" class="archive__subtitle">2012</h2> -->
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Hobbiton - Uses cases where AI can deliver great returns</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Aug 20, 2021

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>One often comes across organizations trying to apply AI to problems when it is really not
                                needed. Such organizations often end up doing so because either someone in the org wants
                                to
                                look cool or a CXO in the company wants to start doing AI (mostly out of FOMO or
                                ill-informed media articles with lofty claims). AI is just a tool to solve problems
                                (though
                                a powerful one), just like other problem-solving tools such as engineering, or
                                operations.
                                Today AI can solve some problems quickly & very well which was not possible until even a
                                decade ago. But that doesn’t mean AI is a sledgehammer for every difficult problem.
                                Despite
                                crazy advances in the last decade, AI is a very nascent, fragile and expensive
                                technology
                                and must be applied after due thought and not as a go-to approach for every problem in
                                the
                                world.</p>
                            <p>
                                One of my favorite examples of this is Google’s approach to “searching for special
                                characters in Google Docs”. Here is the problem statement: Most users who create docs or
                                decks once in a while use special characters. But it is very hard to find the right
                                special
                                character when you need it. Given the large number of special characters that exist, one
                                cannot show all of them to the user. To facilitate quick accessibility, one requires the
                                ability to search for them. However, there is one particular problem with special
                                characters
                                - most users cannot remember them by name (try recalling names of 10 or more special
                                characters yourself). This renders “textual search” useless. So, how does one solve
                                this?
                                Visual search!


                            <p class="center two-thirds"><a href="/images/Google-Doc-Draw-Characters.gif"><img
                                        src="/images/Google-Doc-Draw-Characters.gif"></a></p>

                            </p>
                            <div class="archive__item-excerpt">
                                <p>Google used a very simple but powerful observation - most users can very easily
                                    recall
                                    how the special character that they need looks like, unlike their name. So, they
                                    provided a small sketch pad for users to draw what they remember and use the
                                    concepts
                                    from computer vision (Sketch-RNN) to suggest a few closest options based on the
                                    visual
                                    match. The same concept was later used to power Auto draw.
                                </p>
                                <p>

                                    I often use this example to drive home the point that one often needs to think from
                                    first principles when thinking of AI-powered use cases. For the above-mentioned
                                    example,
                                    the more you think the more you will realize:</p>
                                <p>

                                <ul>
                                    <li>The problem could not have been solved by traditional engineering approaches.
                                    </li>
                                    <li>
                                        It is a very well-defined narrow problem statement.
                                    </li>
                                    <li>
                                        The core AI concept (Sketch-RNN) was just right to solve this problem statement
                                        well.
                                    </li>
                                    <li>
                                        The solution (powered by AI in this case) really helped to solve the user’s pain
                                        point and deliver happiness.
                                    </li>

                                </ul>
                                </p>


                            </div>

                            <div class="archive__item-excerpt">
                                Having said that - it is not that this application of AI changed the fate of google
                                docs.
                                More on changing the trajectory of products using AI in a separate post. Stay tuned!

                            </div>
                        </div>
                    </article>
                </div>

            </div>
            <h2 id="2013" class="archive__subtitle">2016</h2>

            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Great resources on CNN</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Dec 16, 2016

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>I am new to the world of CNNs. While I have worked with neural nets in the area of text,
                                when it comes to CNNs I have little knowledge. There are some awesome resources on the
                                internet to learn on CNNs from ground zero. </p>
                            <p>
                                <strong><a href=" https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner">Basics
                                        of
                                        CNN</a></strong>
                                Guide-To-Understanding-Convolutional-Neural-Networks
                                3 part blog series. Builds the initial intuition very well.



                            <p>Another good resource is this <strong><a
                                        href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">Blog by
                                        Ujjwal
                                    </a></strong></p>

                            </p>
                            <p>Adam Harley's
                                <strong><a href="http://scs.ryerson.ca/~aharley/neural-networks/">
                                        Blog</a></strong> on basic of CNNs.
                                Its bit lengthy but if you are confortable with the key ideas discussed in first 2 blogs
                                by Adesh and Ujjwal, this is a great post.
                            </p>

                            <div class="archive__item-excerpt">

                                Wanna get a feel of CNNs in action ? check this <a
                                    href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html"> <strong>awesome
                                        visualization by Adam
                                        Harley</strong></a>. I highly recomend to play
                                with it.


                            </div>
                        </div>
                    </article>
                </div>

            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Dynamic Plotting in Python</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Dec 11, 2016

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">


                            <p>
                                In my work I am often want to visualize how the data or some aspect of model changes.
                                This requires to have plots/graph which get Dynamically or Live updates - I have a bunch
                                of values. One or more of these values keep on changing with time. I want to visualize
                                these changes using plots.
                            </p>
                            <p>

                                When I looking for a solution, I did not come across an elegent one. So tried piecing
                                together a solution myself.</p>



                            <p>
                                For simplicity, imagine we have M data points with a set of initial values. Further,
                                these vaues get updated/changed, so we have a set pf new M values. This happens N times.
                                This can be captured via a matrix 2D matrix A of (m x n) dimension where each row is a
                                set of values.
                            </p>

                            </p>
                            <p>
                                We record the initial set of values, Then these values get updated, then the update
                                happens again, and again. Row 1 stores the initial values, row 2 stores the subsequent
                                updated values, row 3 stores values after next update, so on and so forth. In esence,
                                the matrix A stores the entire history of values.
                            </p>
                            <p>
                                Now we will like to plot these values. Where the graph starts with values in first row,
                                then gets updated to values in 2nd row, then gets updated tp values in 3rd row, so on
                                and so forth. <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/Dynamic%20or%20Live%20update%20of%20a%20Plot.ipynb"><strong>This
                                        notebook</strong></a>
                                is about how to plot such graphs
                            </p>
                            <div class="archive__item-excerpt">

                                <p>
                                    This is especially useful in machine learning, where you want to visualize how a
                                    particular property of model/data evolves with time (training)

                                    Our matrix is of MxN dimensions, initialised randonly.
                                </p>
                                <p class="center two-thirds"><a href="/images/image_1.png"><img
                                            src="/images/image_1.png"></a></p>
                                <p>gunicorn server up and running
                                    Lets hit the server with a POST request. Open another terminal window and type in:
                                </p>
                                <p>

                                    All the code in the snippets above can be found in the following <strong><a
                                            href="https://github.com/anujgupta82/Musings/blob/master/Dynamic%20or%20Live%20update%20of%20a%20Plot.ipynb">jupyter
                                            notebook</a></strong>.
                                    If you face any issue with the code, please open a <strong><a
                                            href="https://github.com/anujgupta82/Musings/issues"></a>New
                                        issue</strong> on Github.
                                </p>
                            </div>
                        </div>
                    </article>
                </div>

            </div>
            <h2 id="2013" class="archive__subtitle">2014</h2>


            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Deploying ML models - Part 2</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Nov 09, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Deploy ML model using Falcon</strong></p>
                            <h3>Falcon</h3>

                            <p>In the last blog, we used flask to deploy our ML model. Today, we will be exploring a
                                different framework to achieve the same - Falcon. Falcon is pretty simple to work with.
                                Lets get coding :</p>

                            <h4>Install Falcon</h4>

                            <p>Load your virtual environment and execute</p>

                            <pre><code>pip install falcon
                            </code></pre>

                            <p>I used python 2.7 and falcon==1.1.0. This will get falcon installed.</p>

                            <h4>Bare bones Example</h4>

                            <p>The code consists if 2 files - <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/falcon/app.py">app.py</a>
                                (contains app structure and end points) and <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/falcon/functionality.py">functionality.py</a>
                                (contains the code to support the functionality).</p>


                            <h4>app.py</h4>

                            <pre><code>import functionality

                            api = application = falcon.API()

                            hello_world = functionality.hello_world()

                            api.add_route('/hi', hello_world)
                            </code></pre>

                            <p>All this code does is:</p>
                            <ul>
                                <li>Imports the falcon package and creates a basic application.</li>
                                <li>Accesses the hello_world object from functionality.py and creates an endpoint 'hi'
                                    where, when data is sent via a POST request, an appropriate function of the
                                    hello_world object is invoked.</li>
                            </ul>

                            <h4>functionality.py</h4>

                            <pre><code>import falcon
                            import json

                            class hello_world(object):
                            def __init__(self):
                                print "init"

                            def on_post(self, req, resp):
                                print "post: hello_world"
                                result = {}

                                result['msg'] = "hello world"
                                resp.status = falcon.HTTP_200
                                resp.body = json.dumps(result, encoding='utf-8')
                            </code></pre>

                            <p>Here, the code does the following:</p>
                            <ul>
                                <li>Creates a class <code>hello_world</code> with <code>on_post()</code>, which takes a
                                    request and response object.</li>
                                <li>Consumes the request object and sets the attributes of the response object.</li>
                            </ul>

                            <h4>Show time:</h4>

                            <p><strong>Prerequisite:</strong> You need to install the gunicorn server. Load your virtual
                                environment and execute:</p>

                            <pre><code>pip install gunicorn
                            </code></pre>

                            <p>I used Python 2.7 and gunicorn==19.6.0</p>

                            <p><strong>Run the following steps in terminal:</strong></p>

                            <ol>
                                <li> Use cd to navigate to the directory where app.py is saved.</li>

                                <li>gunicorn app</li>
                            </ol>
                            <p>
                                This should get the gunicorn server up and running :
                            </p>

                            <p class="center two-thirds"><a href="/images/ml_models_2/image_1.png"><img
                                        src="/images/ml_models_2/image_1.png"></a></p>
                            <p>gunicorn server up and running</p>
                            <p>Lets hit the server with a POST request. Open another terminal window and type in:</p>

                            <pre><code>curl -i -H "Content-Type: application/json" -X POST http://127.0.0.1:8000/hi
</code></pre>

                            <p>On the client terminal, you should see a <code>200 OK</code> followed by a JSON
                                containing our "hello world" message.</p>

                            <p class="center two-thirds"><a href="/images/ml_models_2/image_2.png"><img
                                        src="/images/ml_models_2/image_2.png"></a></p>
                            <p>On the server terminal you should see our print statement in on_post().
                            </p>

                            <p class="center two-thirds"><a href="/images/ml_models_2/image_3.png"><img
                                        src="/images/ml_models_2/image_3.png"></a></p>

                            <p>Congrats, your first application in Falcon is up and working!</p>

                            <p>Wanna read more on Falcon? Head to <a
                                    href="http://falcon.readthedocs.io/en/stable/user/tutorial.html">Falcon’s page</a>.
                            </p>

                            <h3>FALCON VS FLASK:</h3>

                            <p>I am told Falcon is lightweight. I am not an expert on this topic, here are a couple of
                                links if you wish to take a deep dive into Flask vs Falcon: <a
                                    href="http://klen.github.io/py-frameworks-bench/">Python web frameworks
                                    benchmarking</a>, <a
                                    href="https://www.reddit.com/r/Python/comments/4rq19c/your_choice_of_rest_framework_flask_vs_falcon/">reddit
                                    thread</a>, <a href="https://news.ycombinator.com/item?id=8835776">hacker news</a>,
                                <a href="https://www.slant.co/versus/1398/1744/~flask_vs_falcon">slant</a>.
                            </p>

                            <p>We have a model that is up and running as a service. Now you can go ahead and add more
                                functionality like resetting the model, training the model if not already trained, and a
                                lot more.</p>

                            <p>If you face any issue with the code, please open a "<a
                                    href="https://github.com/anujgupta82/Musings/issues">New issue</a>" on Github. All
                                the above code files are available <a
                                    href="https://github.com/anujgupta82/Musings/tree/master/falcon">here</a>.</p>


                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Deploying ML models - Part 1</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Nov 04, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Deploy ML model using Flask</strong></p>
                            <p><strong>Flask</strong></p>
                            <p>Flask is a lightweight Python web framework to create microservices. Wanna read
                                <a
                                    href="https://code.tutsplus.com/tutorials/an-introduction-to-pythons-flask-framework--net-28822">more</a>
                                ? I am a ML guy, and this sounds complex :-( Rather than reading lets code a simple one
                                quickly !
                            </p>
                            <h4>Install Flask</h4>

                            <p>To install Flask, use the following command:</p>

                            <pre><code>pip install flask</code></pre>

                            <p>I used Python 2.7 and Flask version 0.11.1</p>

                            <h4>Bare Bones Example</h4>

                            <p>Open an editor and copy-paste the code from my <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/flask/simple_app.py">GitHub
                                    repository</a>:</p>
                            <pre>
                                <code>from flask import Flask

                                        app = Flask(__name__)
                                        
                                        @app.route('/1')   # path to resource on server
                                        def index_1():        # action to take
                                          return "Hello_world 1"
                                        
                                        @app.route('/2')
                                        def index_2():
                                          return "Hello_world 2"
                                        
                                        if __name__ == '__main__':
                                          app.run(debug=True)
                                </code>
                            </pre>

                            <p>To run this:</p>

                            <ol>
                                <li>Save it as <code>simple_app.py</code></li>
                                <li>Install Flask in your virtual environment using <code>pip install Flask</code></li>
                                <li>Open terminal, go to the directory where <code>simple_app.py</code> is saved. Run
                                    the following two commands:</li>
                            </ol>

                            <pre><code>export FLASK_APP=simple_app.py
                                        flask run
                                        </code></pre>

                            <p>This should have the Flask server up and running on <a
                                    href="http://127.0.0.1:5000">http://127.0.0.1:5000</a></p>

                            <p class="center two-thirds"><a href="/images/ml_models_1/image_1.png"><img
                                        src="/images/ml_models_1/image_1.png"></a></p>

                            <p>Flask Server up and running</p>


                            <p>If you see the code carefully it says - we have 2 resources with relative URIs as
                                <code>/1</code> and <code>/2</code>. Let's access them. Go to your browser and type <a
                                    href="http://127.0.0.1:5000/1">http://127.0.0.1:5000/1</a>
                            </p>

                            <p>This should fire the function <code>index_1()</code> function and give the following
                                output on the command prompt:</p>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_2.png"><img
                                        src="/images/ml_models_1/image_2.png"></a></p>
                            <p>Output from function index_1</p>

                            <p>Like wise <a href="http://127.0.0.1:5000/2">http://127.0.0.1:5000/2</a> should work. This
                                is a simple flask application. (Oh yeah! this sounds easy, lets move on)</p>

                            <h4>REST (in peace)</h4>

                            <p>There are a couple of terms that are part and parcel of micro services. Lets quickly
                                understand something about them:</p>

                            <ol>
                                <li><strong>API:</strong> Application Program Interface - set of routines, protocols,
                                    and tools for building software applications.</li>
                                <li><strong>API Endpoint:</strong> It's one end of a communication channel, so often
                                    this would be represented as the URL of a server or service. In our example
                                    "<code>http://127.0.0.1:5000/1</code>".</li>
                                <li><strong>REST:</strong> underlying architectural principle of the web.
                                    Read these awesome <a
                                        href="https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming/671132#671132">stackoverflow
                                        answer</a> and this brilliant <a
                                        href="http://web.archive.org/web/20130116005443/http://tomayko.com/writings/rest-to-my-wife">post</a>
                                    from Ryan Tomayko and this <a
                                        href="https://martinfowler.com/articles/richardsonMaturityModel.html">post</a>
                                    from Martin Fowler to understand the same.</li>
                            </ol>

                            <p>In nutshell, you need to have - GET, POST, PUT, DELETE.</p>

                            <p>Lets add this to our <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/flask/RESTful_app.py">code</a>.
                                To see this in action, run the server (like previously), go to terminal and type:</p>

                            <p>To see this in action, run the server (like previously), go to the terminal and type:</p>

                            <pre><code>curl -i http://localhost:5000/tasks
                            </code></pre>

                            <p>or</p>

                            <pre><code>curl -i -X GET http://localhost:5000/tasks
                                </code></pre>

                            <p>Both commands will give the same output:</p>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_3.png"><img
                                        src="/images/ml_models_1/image_3.png"></a></p>
                            <p>Your server terminal will show "200" (success) for both the requests.
                            </p>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_4.png"><img
                                        src="/images/ml_models_1/image_4.png"></a></p>

                            <h4>RESTful App</h4>

                            <p>Lets add other parts of RESTful to out code. Here it is. To see this in action, run the
                                server (like previously), go to terminal and type:</p>

                            <ol>
                                <li start="1"><strong>Get All tasks:</strong></li>
                            </ol>

                            <pre><code>curl -i http://localhost:5000/tasks/
                                        </code></pre>

                            <ol start="2">
                                <li><strong>Get a specific task:</strong></li>
                            </ol>

                            <pre><code>curl -i http://localhost:5000/tasks/2
                                        </code></pre>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_5.png"><img
                                        src="/images/ml_models_1/image_5.png"></a></p>

                            <p>Since there is no task with id=4, lets see what happens when we try to get that:</p>

                            <pre><code>curl -i http://localhost:5000/tasks/4</code></pre>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_6.png"><img
                                        src="/images/ml_models_1/image_6.png"></a></p>
                            <p>Error. Task with id=4 does not exists</p>
                            <ol start="3">
                                <li><strong>Add a task:</strong></li>
                            </ol>

                            <pre><code>curl -i -H "Content-Type: application/json" -X POST -d '{"title":"Read a book"}' http://localhost:5000/tasks/</code></pre>

                            <ol start="4">
                                <li><strong>Update a specific task:</strong></li>
                            </ol>

                            <pre><code>curl -i -H "Content-Type: application/json" -X PUT -d '{"done":true}' http://localhost:5000/tasks/2</code></pre>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_7.png"><img
                                        src="/images/ml_models_1/image_7.png"></a></p>

                            <ol start="5">
                                <li><strong>Delete a specific task: </strong></li>
                            </ol>
                            <p>Delete a specific task:</p>
                            <pre><code>curl -i -X DELETE http://localhost:5000/tasks/2</code></pre>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_8.png"><img
                                        src="/images/ml_models_1/image_8.png"></a></p>
                            <p>task with id=2 successfully deleted</p>
                            <p>ML APP</p>

                            <p>Its all great until now, what about the core issue – ML model as microservice ? Here we
                                go:</p>

                            <pre><code>from flask import Flask, jsonify, request, abort
                            import pickle
                            import numpy as np

                            app = Flask(__name__)
                            model_file_path = "./../models/final_model.pkl"
                            model = None

                            def get_prediction(X):
                            X_i = X.reshape(1, 2)
                            print "X_i.shape"
                            print X_i.shape#load the model if not already done
                            
                            global model
                            if model == None:
                                model = pickle.load(open(model_file_path, 'rb'))#make prediction and return the same
                                prediction = model.predict(X_i)[0]

                            return prediction

                            @app.route('/predict', methods=['POST'])
                            def predict():
                            if not request.json or not 'X1' in request.json or not 'X2' in request.json:
                                abort(404)

                            X1 = request.json['X1']
                            X2 = request.json['X2']

                            X1_ = np.float64(X1)
                            X2_ = np.float64(X2)
                            X = np.array([X1_, X2_])
                            prediction = get_prediction(X)

                            return jsonify({'prediction':prediction})

                            if __name__ == '__main__':
                            app.run(debug=True)
                            </code></pre>

                            <p>To run this code, get the server up and running and then fire the command below from
                                another terminal.</p>

                            <pre><code>curl -i -H "Content-Type: application/json" -X POST -d '{"X1":"61.1", "X2":"17.3"}' http://localhost:5000/predict
</code></pre>

                            <p>Complete code is <a
                                    href="https://github.com/anujgupta82/Musings/blob/master/flask/ML_app.py">here</a>.
                                It has lot of print statements. You should see these statements printing the relevant
                                stuff on the server terminal.</p>

                            <p class="center two-thirds"><a href="/images/ml_models_1/image_9.png"><img
                                        src="/images/ml_models_1/image_9.png"></a></p>
                            <p>Model prediction</p>
                            <p class="center two-thirds"><a href="/images/ml_models_1/image_10.png"><img
                                        src="/images/ml_models_1/image_10.png"></a></p>
                            <p>Lets understand some key aspects of this code. Here, <code>predict()</code> handles any
                                POST request coming on <code>/predict</code> on the server. We extract the payload –
                                components of input vector – these cannot be sent from client as numpy arrays. These
                                components come in as unicode strings. Hence, we transform them explicitly into
                                <code>numpy.float64</code> and then make a numpy array on the server side. There is an
                                elegant way to do it, which we will see in short while.
                            </p>

                            <p>Once we have the payload in right format, we invoke the function –
                                <code>get_prediction()</code>. Its main job is load the model into memory if not already
                                loaded, and fire the model on input for getting the prediction.
                            </p>

                            <p>We have a model that is up and running as service. Now you can go ahead and add more
                                functionality like resetting the model, training the model if not already trained, and
                                lot more.</p>

                            <p>If you face any issue with the code, please open a "<a
                                    href="https://github.com/anujgupta82/Musings/issues">New issue</a>" on Github. All
                                the above 4 code files are available <a
                                    href="https://github.com/anujgupta82/Musings/tree/master/flask">here</a>.</p>

                            <!-- ============================= -->




                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Deploying Machine Learning models</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Nov 04, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Quick ways to deploy and test ML models</strong></p>

                            <h3>Introduction</h3>

                            <p>I have often heard Data scientist/ML people asking "I have a ML model thats doing well on
                                test data, how do I deploy it in production environment ?" Recently I have been
                                exploring the same, so sharing some of my findings and ways to achieve the same. Here
                                focus will be on deployment and not developing a model - hence, for simplicity, we will
                                assume we have a pre-trainied, fine tuned <a
                                    href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html">scikit
                                    model</a> ready to be deployed.</p>

                            <p>This is a 3 part blog series. We will see how to deploy a ML model as a microservice. We
                                will see 3 different ways of doing the same using:</p>

                            <ol>
                                <li>Flask</li>
                                <li>Falcon</li>
                                <li>Jupyter notebook as service (Wow!)</li>
                            </ol>

                            <h3>Microservice - what and why ?</h3>

                            <p>Microserivce is an architecture pattern. It can best be thought as being completely
                                opposite of Monolithic architecture (<a
                                    href="https://www.thoughtworks.com/insights/blog/monoliths-are-bad-design-and-you-know-it">problems</a>).
                                The central idea is to break the system/applications into small chunks(services) based
                                on functionality. Each chunk does a specicifc job and does only that. These services
                                talk to each other using HTTP/REST (synchronous or asynchronous). Want to take a deep
                                dive ? I suggest read <a
                                    href="https://www.quora.com/What-is-Microservices-Architecture">quora
                                    answer</a> and
                                <a href="https://www.martinfowler.com/articles/microservices.html">Martin Fowler's
                                    article</a>.
                            </p>






                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - summary</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Sep 14, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Take home on Computing Gradients that go into training Neural Nets</strong></p>
                            <p><strong>Generalization</strong></p>
                            <p>In this post, based on our conclusions in last post, we will try and generalise a
                                strategy to compute gradients for arbit networks, as shown in figure below:
                            </p>

                            <p class="center two-thirds"><a href="/images/NN_generic.jpeg"><img
                                        src="/images/NN_generic.jpeg"></a>
                            </p>


                            <p>Imagine we have a (Feed forward) network with 1 input layer \(L_0\), 1 output layer
                                \(L_3\), and 2 hidden layers \(L_1\), \(L_2\) respectively. Further, let \(l_i\) be the
                                output of layer \(L_i\). Also, by design, \(l_1 = X\) [input] and \(l_3 = \hat{y}\)
                                [output]. Let \(W_{ij}\) be weights between layers \(L_i\) and \(L_j\). We have 3 weight
                                matrices - \(W_{01}\), \(W_{12}\), and \(W_{23}\).</p>


                            <table>
                                <thead>
                                    <tr>
                                        <th>Tables</th>
                                        <th style="text-align:center;">Are</th>
                                        <th style="text-align:right;">Cool</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>col 1 is</td>
                                        <td style="text-align:center;">left-aligned</td>
                                        <td style="text-align:right;">$1600</td>
                                    </tr>
                                    <tr>
                                        <td>col 2 is</td>
                                        <td style="text-align:center;">centered</td>
                                        <td style="text-align:right;">$12</td>
                                    </tr>
                                    <tr>
                                        <td>col 3 is</td>
                                        <td style="text-align:center;">right-aligned</td>
                                        <td style="text-align:right;">$1</td>
                                    </tr>
                                </tbody>
                            </table>

                            <table>
                                <thead>
                                    <tr>
                                        <th>Name</th>
                                        <th>Lunch order</th>
                                        <th>Spicy</th>
                                        <th style="text-align:right;">Owes</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Joan</td>
                                        <td>saag paneer</td>
                                        <td>medium</td>
                                        <td style="text-align:right;">$11</td>
                                    </tr>
                                    <tr>
                                        <td>Sally</td>
                                        <td>vindaloo</td>
                                        <td>mild</td>
                                        <td style="text-align:right;">$14</td>
                                    </tr>
                                    <tr>
                                        <td>Erin</td>
                                        <td>lamb madras</td>
                                        <td>HOT</td>
                                        <td style="text-align:right;">$5</td>
                                    </tr>
                                </tbody>
                            </table>

                            <table>
                                <thead>
                                    <tr>
                                        <th>First Header</th>
                                        <th style="text-align:center;">Second Header</th>
                                        <th style="text-align:right;">Third Header</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Content</td>
                                        <td colspan="2">*Long Cell*</td>
                                    </tr>
                                    <tr>
                                        <td>Content</td>
                                        <td style="text-align:center;font-weight:bold;">Cell</td>
                                        <td>Cell</td>
                                    </tr>
                                </tbody>
                            </table>

                            <table>
                                <tbody>
                                    <tr>
                                        <td>New section</td>
                                        <td>More</td>
                                        <td>Data</td>
                                    </tr>
                                    <tr>
                                        <td>And more</td>
                                        <td>With an escaped '|'</td>
                                        <td></td>
                                    </tr>
                                </tbody>
                            </table>

                            <table>
                                <thead>
                                    <tr>
                                        <th>foo</th>
                                        <th>bar</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>baz</td>
                                        <td>bim</td>
                                    </tr>
                                </tbody>
                            </table>


                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - Part 4b</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Sep 11, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Part 4 of computing gradients for training Neural Nets</strong></p>
                            <p><strong>2 layer network, single training example (vector)</strong></p>
                            <p>This is in continuation of last
                                post where we derived
                                gradients for 2 layer network where hidden layer has only 1 node.
                            </p>
                            <h4>1 hidden layer with \(\geq\) 2 nodes</h4>
                            <p>We will derive gradients for hidden layer with 2 nodes. 3 or more nodes is a straight
                                forward extension.
                            </p>

                            <p class="center two-thirds"><a href="/images/NN_4_2.jpeg"><img
                                        src="/images/NN_4_2.jpeg"></a></p>

                            <p>Neural net with 2 layer, 2 nodes in hidden layer. Input is a vector</p>

                            <p>First layer (\(l_1\)) has weight matrix <span>$$[W_1]_{\scriptscriptstyle 3 \times
                                    2}$$:</span></p>

                            $$
                            \begin{equation}
                            W_1 = \begin{bmatrix}
                            w_{1}^{11} & w_{1}^{12} \\
                            w_{1}^{21} & w_{1}^{22} \\
                            w_{1}^{31} & w_{1}^{32} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <p>Second layer (\(l_2\)) has weight matrix <span>$$[W_2]_{\scriptscriptstyle 3 \times
                                    2}$$:</span></p>

                            $$
                            \begin{equation}
                            W_2 = \begin{bmatrix}
                            w_{2}^{1} \\
                            w_{2}^{2} \\
                            \end{bmatrix}
                            \end{equation}
                            $$
                            <h5>Input & Output definitions</h5>

                            <p>Exactly same as previous setting. Input is \((\vec{X},y)\): \(\vec{X}\) is a vector,
                                while \(y\) is a scalar.</p>

                            <p>\(X = [x^1 ~~x^2 ~~x^3]\) &nbsp; &nbsp; &nbsp; \(x^i = i^{th}\) component of \(\vec{X}\).
                            </p>

                            <p>Thus, in matrix form \(x,y\) are \([X]_{\scriptscriptstyle 1\times 3}\) and
                                \([y]_{\scriptscriptstyle 1\times 1}\).</p>

                            <p>Let \( l_1 \) be output of layer 1 (hidden layer in this case). In matrix format,
                                \([l_1]_{\scriptscriptstyle 1\times 1}\)</p>

                            $$
                            \begin{align}
                            l_1 & = \sigma ([X] . [W_1]) \label{ref130} \tag{30} \\
                            & = \frac{1}{1 + e^{-[X] . [W_1]}} \label{ref131} \tag{31} \\
                            \end{align}
                            $$
                            <p> \( l_1 \) has 2 components - \( l_1^1 \) and \( l_1^2 \), given by:</p>

                            $$
                            \begin{equation}
                            l_1=\begin{bmatrix}
                            l_{1}^{1} & l_{1}^{2} \\
                            \end{bmatrix}
                            \label{ref132} \tag{32}
                            \end{equation}
                            $$

                            $$
                            \begin{align}
                            l_1^1 = \frac{1}{1 + e^{-(x^1 \times w_1^{11} + x^2 \times w_1^{21} + x^3 \times w_1^{31})}}
                            \label{ref133} \tag{33} \\
                            l_1^2 = \frac{1}{1 + e^{-(x^1 \times w_1^{12} + x^2 \times w_1^{22} + x^3 \times w_1^{32})}}
                            \label{ref134} \tag{34} \\
                            \end{align}
                            $$
                            <p>Let \( \hat{y} \) be predicted output. Then as per diagram, it is also the output of
                                layer 2 (\( l_2 \)). In matrix format, \([\hat{y}]_{\scriptscriptstyle 1\times 1}\)</p>

                            $$
                            \begin{align}
                            \hat{y} & = \sigma ([l_1] . [W_2]) \label{ref135} \tag{35} \\
                            & = \frac{1}{1 + e^{-[l_1] . [W_2]}} \label{ref136} \tag{36} \\
                            & = \frac{1}{1 + e^{-(l_1^1 w_2^1 + l_1^2 w_2^2)}} \label{ref137} \tag{37} \\
                            \end{align}
                            $$

                            <p><strong>Loss</strong></p>
                            <p>Like before, we will use half of squared error loss. \( L = \frac{1}{2} (y - \hat{y})^{2}
                                \)</p>

                            <p><strong>Gradients</strong></p>
                            <p>There are 2 set of gradients: \(\nabla_{W_1} L\) and \(\nabla_{W_2} L\). Let us first
                                compute \(\nabla_{W_2} L\)</p>

                            <p><strong>\([\nabla_{W_2} L]_{\scriptscriptstyle 2\times 1}\)</strong></p>

                            $$
                            \begin{equation}
                            \nabla_{W_2} L = \frac{\partial L}{\partial W_2} \\
                            \nabla_{W_2} L = \begin{bmatrix}
                            \frac{\partial L}{\partial w_{2}^{1}} \\
                            \frac{\partial L}{\partial w_{2}^{2}} \\
                            \end{bmatrix}
                            \label{ref140} \tag{40}
                            \end{equation}
                            $$

                            <p>Lets, first compute \(\frac{\partial L}{\partial w_{2}^{1}}\):</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_2^1} & = \frac{\partial L}{\partial \hat{y}} \times
                            \frac{\partial \hat{y}}{\partial w_2^1} \label{ref141} \tag{41}\\
                            \frac{\partial L}{\partial \hat{y}} &= \frac{1}{2} \times 2 \times (y - \hat{y})^{1} \times
                            (-1) \label{ref142} \tag{42}\\

                            \frac{\partial \hat{y}}{\partial w_2^1} &= \big{(} \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)}
                            \times \big{(}1- \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)} \times l_1^1 \dots && \text{using
                            \eqref{ref137}} \\
                            & = \sigma ([l_1] . [W_2]) \times (1- \sigma ([l_1] . [W_2])) \times l_1^1 \dots &&
                            \text{using \eqref{ref136}} \label{ref143} \tag{43}\\
                            & = \hat{y} \times (1- \hat{y}) \times l_1^1 \dots && \text{using \eqref{ref135}}
                            \label{ref144} \tag{44}\\
                            \end{align}
                            $$

                            <p>Substituting \eqref{ref143} & \eqref{ref144} in \eqref{ref141}, we get</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_2^1} &= \big{(} (-1) \times (y - \hat{y}) \big{)} \times
                            \big{(} \hat{y} \times (1- \hat{y}) \times l_1^1 \big{)}\\ \\
                            &= -(y - \hat{y}) \times \hat{y} \times (1- \hat{y}) \times l_1^1 \\
                            &= (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \times l_1^1 \label{ref145} \tag{45} \\
                            \end{align}
                            $$

                            <p>Let,</p>

                            \begin{align}
                            \Delta l_{2} = (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \label{ref146} \tag{46} \\
                            \end{align}

                            <p>Then, eq \eqref{ref145} reduces to:</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_2^1} &= \Delta l_{2} \times l_1^1 \label{ref147} \tag{47} \\
                            \end{align}
                            $$

                            <p>Likewise,</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_2^2} & = \Delta l_{2} \times l_1^2 \label{ref148} \tag{48} \\
                            \end{align}
                            $$

                            <p>Using eq \eqref{ref147} and \eqref{ref148} in \eqref{ref140}, we get:</p>

                            $$
                            \begin{equation}
                            \nabla_{W_2} L = \begin{bmatrix}
                            \Delta l_{2} \times l_1^1 \\
                            \Delta l_{2} \times l_1^2 \\
                            \end{bmatrix}
                            \label{ref149} \tag{49}
                            \end{equation}
                            $$
                            <p>$$
                                \frac{\partial L}{\partial W_2} = \left[ \begin{array}{c} l_1^1 \\ l_1^2 \end{array}
                                \right]_{\scriptscriptstyle 2 \times 1}. \left[ \Delta l_{2} \right]_{\scriptscriptstyle
                                1 \times 1}
                                $$</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_2} &= [l_{1}]^\intercal . \Delta l_{2} \label{ref1491}
                            \tag{49.1} \\
                            \end{align}
                            $$

                            <p>\([\nabla_{W_1} L]_{\scriptscriptstyle 3\times 2}\)</p>

                            $$
                            \begin{equation}
                            \nabla_{W_1} L = \frac{\partial L}{\partial W_1} \\
                            \nabla_{W_1} L = \begin{bmatrix}
                            \frac{\partial L}{\partial w_{1}^{11}} & \frac{\partial L}{\partial w_{1}^{12}}\\
                            \frac{\partial L}{\partial w_{1}^{21}} & \frac{\partial L}{\partial w_{1}^{22}}\\
                            \frac{\partial L}{\partial w_{1}^{31}} & \frac{\partial L}{\partial w_{1}^{32}}\\
                            \end{bmatrix}
                            \label{ref150} \tag{50}
                            \end{equation}
                            $$

                            <p>Let's first focus on \(\frac{\partial L}{\partial w_{1}^{11}}\):</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{11}} & = \frac{\partial L}{\partial \hat{y}} \times
                            \frac{\partial \hat{y}}{\partial l_1^1} \times \frac{\partial l_1^1}{\partial
                            w_1^{11}}\label{ref151} \tag{51}\\
                            \frac{\partial L}{\partial \hat{y}} &= -(y - \hat{y}) \label{ref152} \tag{52}\\

                            \frac{\partial \hat{y}}{\partial l_1^1} &= \bigg( \frac{1}{1 + e^{-[l_1] . [W_2]}} \bigg)
                            \times \bigg(1- \frac{1}{1 + e^{-[l_1] . [W_2]}} \bigg) \times w_2^1 \\
                            & = \sigma ([l_1] . [W_2]) \times (1- \sigma ([l_1] . [W_2])) \times w_2^1 \dots
                            \text{(using \eqref{ref137})} \label{ref153} \tag{53}\\
                            & = \hat{y} \times (1- \hat{y}) \times w_2^1 \dots \text{(using \eqref{ref135})}
                            \label{ref154} \tag{54}\\

                            \frac{\partial l_1^1}{\partial w_1^{11}} &= \bigg( \frac{1}{1 + e^{-(x^1 \times w_1^{11} +
                            x^2 \times w_1^{21} + x^3 \times w_1^{31})}} \bigg) \times \bigg( 1 - \bigg( \frac{1}{1 +
                            e^{-(x^1 \times w_1^{11} + x^2 \times w_1^{21} + x^3 \times w_1^{31})}} \bigg) \bigg) \times
                            x^1 \dots \text{(using \eqref{ref133})} \label{ref155} \tag{55}\\
                            &= (l_1^1) \times (1-l_1^1) \times x^1 \label{ref156} \tag{56}
                            \end{align}
                            $$
                            <p>Using eq \eqref{ref152}, \eqref{ref154} and \eqref{ref156} in eq \eqref{ref151}</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{11}} & = -(y - \hat{y}) \times \hat{y} \times (1- \hat{y})
                            \times w_2^1 \times l_1^1 \times (1-l_1^1) \times x^1 \\
                            & = (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \times w_2^1 \times l_1^1 \times
                            (1-l_1^1) \times x^1 \label{ref157} \tag{57} \\
                            \end{align}
                            $$

                            <p>Now, using eq \eqref{ref146} in \eqref{ref157}</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{11}} & = \Delta l_{2} \times w_2^1 \times l_1^1 \times
                            (1-l_1^1) \times x^1 \label{ref158} \tag{58} \\
                            \end{align}
                            $$
                            <p>Further, let</p>

                            $$
                            \begin{align}
                            \Delta l_{1}^{1} = \Delta l_{2} * w_2^1 \times (l_1^1) \times (1-l_1^1) \label{ref159}
                            \tag{59}
                            \end{align}
                            $$

                            <p>Then,</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{11}} & = \Delta l_{1}^{1} \times x^1 \label{ref160} \tag{60}
                            \end{align}
                            $$

                            <p>Likewise,</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{21}} & = \Delta l_{2} * w_2^1 \times (l_1^1) \times
                            (1-l_1^1) \times x^2 \\
                            &= \Delta l_{1}^{1} \times x^2 \label{ref161} \tag{61}
                            \end{align}
                            $$
                            <p>$$
                                \begin{align}
                                \frac{\partial L}{\partial w_1^{31}} & = \Delta l_{2} * w_2^1 \times (l_1^1) \times
                                (1-l_1^1) \times x^3 \\
                                &= \Delta l_{1}^{1} \times x^3 \label{ref162} \tag{62} \\
                                \end{align}
                                $$</p>

                            <p>Before we proceed further, Eq \eqref{ref160}, \eqref{ref161} and \eqref{ref162} are key
                                take home equations.</p>

                            <p>Now, lets focus on \(\frac{\partial L}{\partial w_{1}^{12}}\):</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{12}} & = \frac{\partial L}{\partial \hat{y}} \times
                            \frac{\partial \hat{y}}{\partial l_1^2} \times \frac{\partial l_1^2}{\partial
                            w_1^{12}}\label{ref163} \tag{63}\\
                            \frac{\partial L}{\partial \hat{y}} &= -(y - \hat{y}) \label{ref164} \tag{64}\\

                            \frac{\partial \hat{y}}{\partial l_1^2} &= \big{(} \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)}
                            \times \big{(}1- \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)} * w_2^2 \\
                            & = \sigma ([l_1] . [W_2]) \times (1- \sigma ([l_1] . [W_2])) * w_2^2 \dots && \text{using
                            \eqref{ref137}} \label{ref165} \tag{65}\\
                            & = \hat{y} \times (1- \hat{y}) * w_2^2 \dots && \text{using \eqref{ref135}} \label{ref166}
                            \tag{66}\\

                            \frac{\partial l_1^2}{\partial w_1^{12}} &= \big{(} \frac{1}{1 + e^{-(x^1 \times w_1^{12} +
                            x^2 \times w_1^{22} + x^3 \times w_1^{32})}} \big{)} \times \big{(} 1 - \big{(} \frac{1}{1 +
                            e^{-(x^1 \times w_1^{12} + x^2 \times w_1^{22} + x^3 \times w_1^{32})}} \big{)} \big{)}
                            \times x^1 \dots && \text{using \eqref{ref133}} \label{ref167} \tag{67}\\
                            &= (l_1^2) \times (1-l_1^2) \times x^1 \label{ref168} \tag{68}
                            \end{align}
                            $$

                            <p>$$
                                \begin{align}
                                \frac{\partial L}{\partial w_1^{12}} & = -(y - \hat{y}) \times \hat{y} \times (1-
                                \hat{y}) * w_2^2 \times (l_1^2) \times (1-l_1^2) \times x^1 \\
                                & = (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) * w_2^2 \times (l_1^2) \times
                                (1-l_1^2) \times x^1 \label{ref169} \tag{69}
                                \end{align}
                                $$</p>

                            <p>Now, using eq \eqref{ref146} in \eqref{ref169} </p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{12}} & = \Delta l_{2} * w_2^2 \times (l_1^2) \times
                            (1-l_1^2) \times x^1 \label{ref170} \tag{70} \\
                            \end{align}
                            $$

                            <p>Further, let</p>

                            $$
                            \begin{align}
                            \Delta l_{1}^{2} = \Delta l_{2} * w_2^2 \times (l_1^2) \times (1-l_1^2) \label{ref171}
                            \tag{71}
                            \end{align}
                            $$
                            <p>Then, </p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{12}} & = \Delta l_{1}^{2} \times x^1 \label{ref172} \tag{72}
                            \end{align}
                            $$

                            <p>Likewise, </p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{22}} & = \Delta l_{2} \times w_2^2 \times (l_1^2) \times
                            (1-l_1^2) \times x^2 \\
                            &= \Delta l_{1}^{2} \times x^2 \label{ref173} \tag{73}
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1^{32}} & = \Delta l_{2} \times w_2^2 \times (l_1^2) \times
                            (1-l_1^2) \times x^3 \\
                            &= \Delta l_{1}^{2} \times x^3 \label{ref174} \tag{73} \\
                            \end{align}
                            $$

                            <p>Now, we have the pieces. We just need to assemble them.</p>

                            <p>Using Eq \eqref{ref160}, \eqref{ref161}, \eqref{ref162} and \eqref{ref172},
                                \eqref{ref173}, \eqref{ref174} in \eqref{ref150}</p>

                            $$
                            \begin{equation}
                            \nabla_{W_1} L = \frac{\partial L}{\partial W_1} \\
                            \nabla_{W_1} L = \begin{bmatrix}
                            \Delta l_{1}^{1} \times x^1 & \Delta l_{1}^{2} \times x^1\\
                            \Delta l_{1}^{1} \times x^2 & \Delta l_{1}^{2} \times x^2\\
                            \Delta l_{1}^{1} \times x^3 & \Delta l_{1}^{2} \times x^3\\
                            \end{bmatrix}
                            \label{ref175} \tag{75}
                            \end{equation}
                            $$

                            <p>Using the notation used in Eq \eqref{ref132}, let </p>

                            $$
                            \begin{equation}
                            \Delta l_1=\begin{bmatrix}
                            \Delta l_{1}^{1} & \Delta l_{1}^{2} \\
                            \end{bmatrix}
                            \label{ref176} \tag{76}
                            \end{equation}
                            $$

                            <p>Using Eq \eqref{ref176} in \eqref{ref175}, we get:</p>

                            $$
                            \begin{align}
                            \left[ \frac{\partial L}{\partial W_1} \right]_{\scriptscriptstyle 3 \times 2} = \left[
                            \begin{array}{c} x^1 \\ x^2 \\ x^3 \end{array} \right]_{\scriptscriptstyle 3 \times 1} .
                            \left[ \Delta l_{1}^{1} \quad \Delta l_{1}^{2} \right]_{\scriptscriptstyle 1 \times 2}
                            \label{ref177} \tag{77}
                            \end{align}
                            $$
                            <p>Note that,</p>

                            $$
                            \begin{align}
                            \Delta l_1 = \left[ \Delta l_{1}^{1} \quad \Delta l_{1}^{2} \right] \tag{76}
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \Delta l_{1}^{1} = \Delta l_{2} * w_2^1 \times (l_1^1) \times (1-l_1^1) \tag{59}
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \Delta l_{1}^{2} = \Delta l_{2} * w_2^2 \times (l_1^2) \times (1-l_1^2) \tag{71}
                            \end{align}
                            $$

                            <p>Thus,</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_1} &= [X]^\intercal . \Delta l_{1} \label{ref178} \tag{78} \\
                            \end{align}
                            $$

                            <p>Therefore, </p>

                            $$
                            \begin{align}
                            \Delta l_1 &= \left[ \Delta l_{2} * w_2^1 \times (l_1^1) \times (1-l_1^1) \quad \Delta l_{2}
                            * w_2^2 \times (l_1^2) \times (1-l_1^2) \right] \\
                            &= (\left[ \Delta l_{2} \right]_{\scriptscriptstyle 1 \times 1} . \left[ W_2 ^\intercal
                            \right]_{\scriptscriptstyle 1 \times 2}) \times (l_1) \times (1-l_1) \label{ref179} \tag{79}
                            \end{align}
                            $$
                            <p><strong>To summarize the key equations:</strong></p>

                            \begin{align}
                            \Delta l_{2} &= (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \tag{46} \\
                            \end{align}

                            \begin{align}
                            \Delta l_{1} &= (\left[ \Delta l_{2} \right] . \left[ W_2 ^\intercal \right]) \times (l_1)
                            \times (1-l_1) \tag{79}\\
                            \end{align}

                            <p>$$
                                \begin{align}
                                \frac{\partial L}{\partial W_1} &= [X]^\intercal . \Delta l_{1} \tag{78} \\
                                \end{align}
                                $$</p>

                            <p>$$
                                \begin{align}
                                \frac{\partial L}{\partial W_2} &= [l_{1}]^\intercal . \Delta l_{2} \tag{49.1} \\
                                \end{align}
                                $$</p>
                            <p>Now, using these 4 equations - \eqref{ref146}, \eqref{ref179}, \eqref{ref1491}, and
                                \eqref{ref178}, one can directly code (bare bones) training algorithm. The following
                                code is borrowed from the <a
                                    href="http://iamtrask.github.io/2015/07/27/python-network-part2/#viewSource">blog
                                    post</a> of Andrew Trask</p>
                            <pre><code>import numpy as np

                                        X = np.array([0,0,1])
                                        y = np.array([0])
                                        
                                        alpha = 0.5  # learning rate - hyperparameter
                                        
                                        W_1 = np.random.random((3,2))
                                        W_2 = np.random.random((2,1))
                                        
                                        for i in range(1000):
                                        
                                            layer_1 = 1/(1+np.exp(-(np.dot(X,W_1))))
                                            layer_2 = 1/(1+np.exp(-(np.dot(layer_1,W_2))))
                                        
                                            layer_2_delta = (layer_2 - y)*(layer_2*(1-layer_2))
                                            layer_1_delta = layer_2_delta.dot(W_2.T)*(layer_1*(1-layer_1))
                                        
                                            W_1 = W_1 - alpha * (layer_1.T).dot(layer_2_delta)
                                            W_2 = W_2 - alpha * (X.T).dot(layer_1_delta)
                                        </code></pre>
                            </code></pre>









                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - Part 4a</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Sep 04, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Part 4 of computing gradients for training Neural Nets</strong></p>
                            <p><strong>2 layer network, single training example (vector)</strong></p>
                            <p>In this post we will consider 2 type of networks. In first network, hidden layer has only
                                1 node while in second
                                network, hidden layer has more
                                than 1 node. Lets start with the case of hidden layer with only 1 node. This part is bit
                                lengthy, but fundamentally not very different from earlier parts. Keep calm and read on
                                :-)
                            </p>
                            <p>1 hidden layer with 1 node</p>
                            <p class="center two-thirds"><a href="/images/NN_4_1.jpeg"><img
                                        src="/images/NN_4_1.jpeg"></a></p>

                            <p>Neural net with 2 layer, 1 node in hidden layer. Input is a vector</p>

                            <p>First layer (\(l_1\)) has weight matrix \([W_1]_{3 \times 1}\)</p>
                            $$
                            \begin{equation}
                            W_1=\begin{bmatrix}
                            w_{1}^{1} \\
                            w_{1}^{2} \\
                            w_{1}^{3} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <p>Second layer (\(l_2\)) has weight matrix \([W_2]_{1 \times 1}\) which is a scalar</p>

                            $$
                            \begin{equation}
                            W_2=\begin{bmatrix}
                            w_{2} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <h5>Input & Output definitions</h5>

                            <p>Input is \((\vec{X},y)\) : \(\vec{X}\) is a vector, while \(y\) is a scalar.</p>

                            <p>\(X = [x^1 ~~x^2 ~~x^3]\) &nbsp; &nbsp; &nbsp; \(x^i = i^{th}\) component of \(\vec{X}\).
                            </p>

                            <p>Thus, in matrix form \(x,y\) are \([X]_{1\times 3}\) and \([y]_{1\times 1}\).</p>

                            <p>Let \( l_1 \) be output of layer 1. In matrix format, \([l_1]_{1\times 1}\)</p>

                            $$
                            \begin{align}
                            l_1 & = \sigma ([X] . [W_1]) \label{ref0} \tag{1.1} \\
                            & = \frac{1}{1 + e^{-[X] . [W_1]}} \label{ref10} \tag{1.2} \\
                            & = \frac{1}{1 + e^{-(x^1 \times w_1^1 + x^2 \times w_1^2 + x^3 \times w_1^3)}}
                            \label{ref101} \tag{1.3}
                            \end{align}
                            $$

                            <p>\( \hat{y} \) is predicted output. In matrix format, \([\hat{y}]_{1\times 1}\)</p>

                            $$
                            \begin{align}
                            \hat{y} & = \sigma ([l_1] . [W_2]) \label{ref11} \tag{2.1} \\
                            & = \frac{1}{1 + e^{-[l_1] . [W_2]}} \label{ref112} \tag{2.2} \\
                            & = \frac{1}{1 + e^{-(l_1 w_2)}} \label{ref113} \tag{2.3} \\
                            \end{align}
                            $$
                            <h5>Loss</h5>
                            <p>Like before, we will use half of squared error loss. \( L = \frac{1}{2} (y - \hat{y})^{2}
                                \)</p>

                            <h5>Gradients</h5>
                            <p>There are 2 sets of gradients: \(\nabla_{W_1} L\) and \(\nabla_{W_2} L\). Let us first
                                compute \(\nabla_{W_2} L\)</p>

                            <p><strong>\([\nabla_{W_2} L]_{1\times 1}\)</strong></p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_2} & = \frac{\partial L}{\partial \hat{y}} \times
                            \frac{\partial \hat{y}}{\partial W_2} \label{ref12} \tag{3}\\
                            \frac{\partial L}{\partial \hat{y}} &= \frac{1}{2} \times 2 \times (y - \hat{y})^{1} \times
                            (-1) \label{ref13} \tag{4}\\
                            \frac{\partial \hat{y}}{\partial W_2} &= \bigg( \frac{1}{1 + e^{-[l_1] . [W_2]}} \bigg)
                            \times \bigg(1- \frac{1}{1 + e^{-[l_1] . [W_2]}} \bigg) \times l_1 \\
                            & = \sigma ([l_1] . [W_2]) \times (1- \sigma ([l_1] . [W_2])) \times l_1 \dots &&
                            \text{using \eqref{ref11}} \label{ref14} \tag{5}\\
                            & = \hat{y} \times (1- \hat{y}) \times l_1 \dots && \text{using \eqref{ref11}} \label{ref15}
                            \tag{6}\\
                            \end{align}
                            $$

                            <p>Substituting \eqref{ref13} & \eqref{ref15} in \eqref{ref12}, we get</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_2} &= \bigg( (-1) \times (y - \hat{y}) \bigg) \times \bigg(
                            \hat{y} \times (1- \hat{y}) \times l_1 \bigg)\\
                            &= \bigg( -(y - \hat{y}) \bigg) \times \bigg( \hat{y} \times (1- \hat{y}) \times l_1
                            \bigg)\\
                            &= (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \times l_1 \label{ref16} \tag{7} \\
                            \end{align}
                            $$


                            <p>Let,</p>

                            \begin{align}
                            \Delta l_{2} &= (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \label{ref17} \tag{8} \\
                            \end{align}

                            <p>Then, using eq \eqref{ref17}, eq \eqref{ref16} reduces to:</p>
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_2} &= \Delta l_{2} \times l_1 \\
                            & = \Delta l_{2} * l_1 \\
                            & = [l_1]^\intercal . \Delta l_{2} \label{ref18} \tag{9} \\
                            \end{align}
                            $$

                            <p><strong>\([\nabla_{W_1} L]_{\scriptscriptstyle 3\times 1}\)</strong></p>

                            <p>Now let us compute \(\nabla_{W_1} L\)</p>

                            $$
                            \begin{equation}
                            \nabla_{W_1} L = \frac{\partial L}{\partial W_1} \\
                            \nabla_{W_1} L = \begin{bmatrix}
                            \frac{\partial L}{\partial w_{1}^{1}} \\
                            \frac{\partial L}{\partial w_{1}^{2}} \\
                            \frac{\partial L}{\partial w_{1}^{3}} \\
                            \end{bmatrix}
                            \label{ref20} \tag{10}
                            \end{equation}
                            $$
                            <p>First, let's compute only \(\frac{\partial L}{\partial w_{1}^{1}}\)</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_{1}^{1}} & = \frac{\partial L}{\partial \hat{y}} \times
                            \frac{\partial \hat{y}}{\partial l_1} \times \frac{\partial l_1}{\partial w_1^1}
                            \label{ref21} \tag{11}\\
                            \frac{\partial L}{\partial \hat{y}} &= \frac{1}{2} \times 2 \times (y - \hat{y})^{1} \times
                            (-1) \label{ref22} \tag{12}\\

                            \frac{\partial \hat{y}}{\partial l_1} &= \big{(} \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)}
                            \times \big{(}1- \frac{1}{1 + e^{-[l_1] . [W_2]}} \big{)} * w_2 \\
                            & = \sigma ([l_1] . [W_2]) \times (1- \sigma ([l_1] . [W_2])) * w_2 \dots && \text{using
                            \eqref{ref11}} \label{ref23} \tag{13}\\
                            & = \hat{y} \times (1- \hat{y}) * w_2 \dots && \text{using \eqref{ref11}} \label{ref24}
                            \tag{14}\\

                            \frac{\partial l_1}{\partial w_1^1} &= \big{(} \frac{1}{1 + e^{-[X] . [W_1]}} \big{)} \times
                            \big{(}1- \frac{1}{1 + e^{-[X] . [W_1]}} \big{)} * x^1 \label{ref25} \tag{15}\\
                            & = l_1 \times (1- l_1) * x^1 \dots && \text{using \eqref{ref11}} \label{ref26} \tag{16}\\

                            \end{align}
                            $$

                            <p>Combining, eq \eqref{ref22}, \eqref{ref24}, and \eqref{ref26}:</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_{1}^{1}} & = \big(-(y - \hat{y}) \big) \times \big( \hat{y}
                            \times (1- \hat{y}) \times w_2 \big) \times \big( l_1 \times (1- l_1) \times x^1 \big) \\
                            & = \big((\hat{y} - y)\hat{y}(1- \hat{y}) \times w_2 \big) \times \big( l_1 \times (1- l_1)
                            \times x^1 \big) \\
                            & = \big(\Delta l_{2} \times w_2 \times l_1 \times (1- l_1) \big) \times x^1 \dots &&
                            \text{using \eqref{ref17}} \label{ref27} \tag{17}\\
                            \end{align}
                            $$
                            <p>Let,</p>

                            \begin{align}
                            \Delta l_{1} = \Delta l_{2} \times w_2 \times l_1 \times (1- l_1) \label{ref28} \tag{18}
                            \end{align}

                            Then, eq \eqref{ref27} reduces to:

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_{1}^{1}} & = \Delta l_{1} \times x^1 \label{ref29} \tag{19} \\
                            \end{align}
                            $$

                            Likewise,

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_{1}^{2}} & = \Delta l_{1} \times x^2 \label{ref30} \tag{20} \\
                            \frac{\partial L}{\partial w_{1}^{3}} & = \Delta l_{1} \times x^3 \label{ref31} \tag{21} \\
                            \end{align}
                            $$

                            <p>Using eq \eqref{ref29}, \eqref{ref30}, and \eqref{ref31} in \eqref{ref20}:</p>

                            $$
                            \begin{equation}
                            \nabla_{W_1} L = \begin{bmatrix}
                            \Delta l_{1} \times x^1 \\
                            \Delta l_{1} \times x^2 \\
                            \Delta l_{1} \times x^3 \\
                            \end{bmatrix}
                            \label{ref32} \tag{22}
                            \end{equation}
                            $$

                            $$
                            \frac{\partial L}{\partial W_1} = \left[ \begin{array}{c} x^1 \\ x^2 \\ x^3 \end{array}
                            \right]_{\scriptscriptstyle 3 \times 1}. \left[ \Delta l_{1} \right]_{\scriptscriptstyle 1
                            \times 1}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W_1} &= [X]^\intercal . \Delta l_{1} \\
                            \end{align}
                            $$
                        </div>
                </div>
                </article>
            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - Part 3</a>
                        </h2>
                        <!-- <p class="page__meta">
                            <i class="fa fa-clock-o" aria-hidden="true"></i>
                            less than 1 minute read
                        </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Aug 30, 2014

                            </time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>1 layer network, multiple training examples (each example is a
                                    vector)</strong></p>
                            <p><strong>Multiple training examples correspond to the scenario of batch training. Each
                                    input is still a vector. Our neural net still has 1 layer.
                                    For simplicity, assume we have 4 examples, each having 3 components.
                                </strong></p>
                            <p class="center two-thirds"><a href="/images/NN_2_2.jpeg"><img
                                        src="/images/NN_2_2.jpeg"></a></p>
                            <h4>Weights</h4>

                            <p>W, weight matrix is $$[W]_{\scriptscriptstyle 3 \times 1}$$</p>

                            $$
                            \begin{equation}
                            W=\begin{bmatrix}
                            w_{1} \\
                            w_{2} \\
                            w_{3} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <h4>Input & Output definitions</h4>

                            <p>Input <strong>X</strong> now is a matrix \( [X]_{\scriptscriptstyle 4 \times 3} \).
                                \(X_i\) is the \(i^{th}\) sample. So, we now have <strong>4</strong> examples \(X_1
                                \ldots X_4\), each of which is a vector with <strong>3</strong> components.
                                \(x_{i}^{j}\) is the \(j^{th}\) component of the \(i^{th}\) sample. So</p>

                            $$
                            \begin{equation}
                            X=\begin{bmatrix}
                            x_{1}^{1} & x_{1}^{2} & x_{1}^{3} \\
                            x_{2}^{1} & x_{2}^{2} & x_{2}^{3} \\
                            x_{3}^{1} & x_{3}^{2} & x_{3}^{3} \\
                            x_{4}^{1} & x_{4}^{2} & x_{4}^{3} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <p>\(\vec{y}\) is a vector.</p>


                            $$
                            \begin{equation}
                            y=\begin{bmatrix}
                            y_{1} \\
                            y_{2} \\
                            y_{3} \\
                            y_{4} \\
                            \end{bmatrix}
                            \end{equation}
                            $$
                            <p>$$y_i$$ = True label for $$i^{th}$$ example.</p>

                            <p>Likewise, $$\vec{\hat{y}}$$ is a vector where</p>


                            $$
                            \begin{equation}
                            \hat{y}=\begin{bmatrix}
                            \hat{y}_{1} \\
                            \hat{y}_{2} \\
                            \hat{y}_{3} \\
                            \hat{y}_{4} \\
                            \end{bmatrix}
                            \end{equation}
                            $$

                            <p>$$\hat{y}_i$$ = predicted label for $$i^{th}$$ example. The value of $$\hat{y}_i$$
                                is computed using \eqref{ref10}:</p>

                            $$
                            \hat{y}_i = \frac{1}{1+e^{-(x_{i}^{1} \times w_1 + x_{i}^{2} \times w_2 + x_{i}^{3} \times
                            w_3)}} \label{ref10} \tag{0}
                            $$

                            <h4>Loss</h4>

                            <p>Like before, we will use half of squared error loss, but in this case, it is the total
                                gap in all 4 predictions. Therefore,</p>

                            $$ L = \sum\limits_{i=1}^{4} \frac{1}{2} (y_i - \hat{y}_i)^{2} $$

                            <h4>Gradients</h4>

                            <p>Let's compute gradients.</p>

                            $$
                            \begin{equation}
                            \nabla_{W} L = \frac{\partial L}{\partial W} \\
                            \nabla_{W} L = \begin{bmatrix}
                            \frac{\partial L}{\partial w_{1}} \\
                            \frac{\partial L}{\partial w_{2}} \\
                            \frac{\partial L}{\partial w_{3}} \\
                            \end{bmatrix}
                            \label{ref11} \tag{1}
                            \end{equation}
                            $$

                            <p>First, let's compute only \( \frac{\partial L}{\partial w_{1}} \)</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= \frac{\partial (\sum\limits_{i=1}^{4} \frac{1}{2} (y_i -
                            \hat{y}_i)^{2})}{\partial w_1} \\
                            & = \sum\limits_{i=1}^{4} \frac{\partial (\frac{1}{2} (y_i - \hat{y}_i)^{2})}{\partial w_1}
                            \\
                            & = \sum\limits_{i=1}^{4} \frac{\partial (\frac{1}{2} (y_i - \hat{y}_i)^{2})}{\partial
                            \hat{y}_i} \times \frac{\partial \hat{y}_i}{w_1} \tag{2} \label{ref12}
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial (\frac{1}{2} (y_i - \hat{y}_i)^{2})}{\partial \hat{y}_i} = (-1) \times (y_i -
                            \hat{y}_i) \tag{3} \label{ref13}
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial \hat{y}_i}{w_1} &= \sigma(x_{i}^{1} \times w_1 + x_{i}^{2} \times w_2 +
                            x_{i}^{3} \times w_3)(1 - \sigma(x_{i}^{1} \times w_1 + x_{i}^{2} \times w_2 + x_{i}^{3}
                            \times w_3)) \times x_{i}^{1} \\
                            & = \sigma( X_i . [W])(1 - \sigma( X_i . [W])) \times x_{i}^{1} \tag{4} \label{ref14}
                            \end{align}
                            $$

                            <p>Using \eqref{ref13} and \eqref{ref14} in \eqref{ref12}, we get:</p>

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= \sum\limits_{i=1}^{4} -(y_i - \hat{y}_i) \cdot
                            [\sigma(X_i \cdot [W])(1 - \sigma(X_i \cdot [W])) \times x_{i}^{1}] \label{ref15} \tag{5} \\
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= -(y_1 - \hat{y}_1) \cdot [\sigma(X_1 \cdot [W])(1 -
                            \sigma(X_1 \cdot [W])) \times x_{1}^{1}] \\
                            &\quad -(y_2 - \hat{y}_2) \cdot [\sigma(X_2 \cdot [W])(1 - \sigma(X_2 \cdot [W])) \times
                            x_{2}^{1}] \\
                            &\quad -(y_3 - \hat{y}_3) \cdot [\sigma(X_3 \cdot [W])(1 - \sigma(X_3 \cdot [W])) \times
                            x_{3}^{1}] \\
                            &\quad -(y_4 - \hat{y}_4) \cdot [\sigma(X_4 \cdot [W])(1 - \sigma(X_4 \cdot [W])) \times
                            x_{4}^{1}] \\
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= (\hat{y}_1 - y_1) \cdot [\sigma(X_1 \cdot [W])(1 -
                            \sigma(X_1 \cdot [W])) \times x_{1}^{1}] + \\
                            &\quad (\hat{y}_2 - y_2) \cdot [\sigma(X_2 \cdot [W])(1 - \sigma(X_2 \cdot [W])) \times
                            x_{2}^{1}] + \\
                            &\quad (\hat{y}_3 - y_3) \cdot [\sigma(X_3 \cdot [W])(1 - \sigma(X_3 \cdot [W])) \times
                            x_{3}^{1}] + \\
                            &\quad (\hat{y}_4 - y_4) \cdot [\sigma(X_4 \cdot [W])(1 - \sigma(X_4 \cdot [W])) \times
                            x_{4}^{1}] \\
                            \end{align}
                            \label{ref16} \tag{6}
                            $$
                            $$
                            \begin{align}
                            \Delta l_{1}^{i} &= ((\hat{y}_i - y_i) \cdot [\sigma(X_i \cdot [W])(1 - \sigma(X_i \cdot
                            [W]))]) \quad \forall i \in (1,4) \label{ref17} \tag{7} \\
                            \end{align}
                            $$

                            Using \eqref{ref17} in \eqref{ref16}, we get:
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= \Delta l_{1}^{1} \times x_{1}^{1} + \Delta l_{1}^{2}
                            \times x_{2}^{1} + \Delta l_{1}^{3} \times x_{3}^{1} + \Delta l_{1}^{4} \times x_{4}^{1}
                            \label{ref18} \tag{8} \\
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_2} &= \Delta l_{1}^{1} \times x_{1}^{2} + \Delta l_{1}^{2}
                            \times x_{2}^{2} + \Delta l_{1}^{3} \times x_{3}^{2} + \Delta l_{1}^{4} \times x_{4}^{2}
                            \label{ref19} \tag{9} \\
                            \end{align}
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_3} &= \Delta l_{1}^{1} \times x_{1}^{3} + \Delta l_{1}^{2}
                            \times x_{2}^{3} + \Delta l_{1}^{3} \times x_{3}^{3} + \Delta l_{1}^{4} \times x_{4}^{3}
                            \label{ref20} \tag{10} \\
                            \end{align}
                            $$

                            $$
                            \begin{equation}
                            \frac{\partial L}{\partial W} = \begin{bmatrix}
                            \Delta l_{1}^{1} \times x_{1}^{1} + \Delta l_{1}^{2} \times x_{2}^{1} + \Delta l_{1}^{3}
                            \times x_{3}^{1} + \Delta l_{1}^{4} \times x_{4}^{1} \\
                            \Delta l_{1}^{1} \times x_{1}^{2} + \Delta l_{1}^{2} \times x_{2}^{2} + \Delta l_{1}^{3}
                            \times x_{3}^{2} + \Delta l_{1}^{4} \times x_{4}^{2} \\
                            \Delta l_{1}^{1} \times x_{1}^{3} + \Delta l_{1}^{2} \times x_{2}^{3} + \Delta l_{1}^{3}
                            \times x_{3}^{3} + \Delta l_{1}^{4} \times x_{4}^{3} \\
                            \end{bmatrix}
                            \label{ref21} \tag{11}
                            \end{equation}
                            $$

                            <p>Simplifying</p>
                            $$
                            \frac{\partial L}{\partial W} = \begin{bmatrix} x_{1}^{1} & x_{2}^{1} & x_{3}^{1} &
                            x_{4}^{1} \\ x_{1}^{2} & x_{2}^{2} & x_{3}^{2} & x_{4}^{2} \\ x_{1}^{3} & x_{2}^{3} &
                            x_{3}^{3} & x_{4}^{3} \end{bmatrix} \cdot \left[ \begin{array}{c} \Delta l_{1}^{1} \\ \Delta
                            l_{1}^{2} \\ \Delta l_{1}^{3} \\ \Delta l_{1}^{4} \end{array} \right]
                            $$

                            $$
                            \frac{\partial L}{\partial W} = \begin{bmatrix} x_{1}^{1} & x_{2}^{1} & x_{3}^{1} &
                            x_{4}^{1} \\ x_{1}^{2} & x_{2}^{2} & x_{3}^{2} & x_{4}^{2} \\ x_{1}^{3} & x_{2}^{3} &
                            x_{3}^{3} & x_{4}^{3} \end{bmatrix} \cdot \left[ \begin{array}{c} \Delta l_{1} \end{array}
                            \right]
                            $$

                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W} &= [X^{T}] \cdot \Delta l_{1} \\
                            \end{align}
                            $$



                        </div>
                </div>
                </article>
            </div>

            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - Part 2</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Aug 28, 2014</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Part 2 of computing gradients for training Neural Nets</strong></p>
                            <p><strong>1 layer network, 1 input (vector)</strong>
                            </p>
                            <p>
                                Our neural net still has 1 layer, but now the input is a vector.

                            </p>
                            <p class="center two-thirds"><a href="/images/NN_2_2.jpeg"><img
                                        src="/images/NN_2_2.jpeg"></a></p>
                            <p>Neural net with 1 layer, but input is vector</p>
                            <p>Input is \( (\vec{X}, y) \): \( \vec{X} \) is a vector, while \( y \) is a scalar.</p>
                            <p>Let \( X = [x^1 ~~x^2 ~~x^3] \) where \( x^i \) is the \( i^{th} \) component of \(
                                \vec{X} \).</p>
                            <p>Thus, in matrix form, \( \vec{x} \) and \( y \) are represented as:</p>
                            <p>\( [X]_{1 \times 3} \) and \( [y]_{1 \times 1} \).</p>
                            <p>Let \( W \), the weight matrix, be:</p>
                            $$
                            \begin{equation}
                            W = \begin{bmatrix}
                            w_{1} \\
                            w_{2} \\
                            w_{3} \\
                            \end{bmatrix}
                            \end{equation}
                            $$
                            <p>Let \( \hat{y} \) be the predicted output. In matrix format, \( [\hat{y}]_{1 \times 1} \)
                                is given by:</p>
                            $$
                            \begin{align}
                            \hat{y} & = \sigma([X] . [W]) \label{ref101} \tag{10.1} \\
                            & = \frac{1}{1 + e^{-[X] . [W]}} \label{ref102} \tag{10.2} \\
                            & = \frac{1}{1 + e^{-(x^1 w_1 + x^2 w_2 + x^3 w_3)}} \label{ref10.3} \tag{10.3}
                            \end{align}
                            $$
                            <p>For the loss function, we use half of the squared error loss:</p>
                            $$ L = \frac{1}{2}(y - \hat{y})^{2} $$
                            <p>Let's first compute the gradients:</p>
                            $$
                            \begin{equation}
                            \nabla_{W} L = \frac{\partial L}{\partial W} \\
                            \nabla_{W} L = \begin{bmatrix}
                            \frac{\partial L}{\partial w_{1}} \\
                            \frac{\partial L}{\partial w_{2}} \\
                            \frac{\partial L}{\partial w_{3}} \\
                            \end{bmatrix}
                            \tag*{11}
                            \end{equation}
                            $$
                            <p>So, let's compute \( \frac{\partial L}{\partial w_{1}} \):</p>
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= \frac{\partial L}{\partial \hat{y}} * \frac{\partial
                            \hat{y}}{\partial w_1} \label{eq:ref12} \tag{12} \\
                            \frac{\partial L}{\partial \hat{y}} &= \frac{1}{2} \times 2 \times (y - \hat{y})^{1} \times
                            (-1) \label{eq:ref13} \tag{13} \\
                            \frac{\partial \hat{y}}{\partial w_1} &= \left( \frac{1}{1 + e^{-[X] \cdot [W]}} \right)
                            \times \left(1- \frac{1}{1 + e^{-[X] \cdot [W]}} \right) \times x_1 \dots \text{using
                            \eqref{eq:ref102} \& \eqref{eq:ref103}} \label{eq:ref14} \tag{14}\\
                            & = \sigma ([X] \cdot [W]) \times (1- \sigma ([X] \cdot [W])) \times x_1 \dots \text{using
                            \eqref{eq:ref101}} & \label{eq:ref15} \tag{15}\\
                            & = \hat{y} \times (1- \hat{y}) \times x_1 \dots \text{using \eqref{eq:ref101}} &
                            \label{eq:ref16} \tag{16}\\
                            \end{align}
                            $$

                            <p>Substituting \eqref{ref13} and \eqref{ref16} into \eqref{ref12}, we get:</p>
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_1} &= \left( (-1) \times (y - \hat{y}) \right) \times \left(
                            \hat{y} \times (1 - \hat{y}) \times x_1 \right) \\
                            & = -(y - \hat{y}) \times \hat{y} \times (1 - \hat{y}) \times x_1 \\
                            & = (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \times x_1
                            \end{align}
                            $$
                            <p>Thus, in general:</p>
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial w_i} &= (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \times
                            x_i \label{ref17} \tag{17}
                            \end{align}
                            $$
                            <p>Using \eqref{ref17} in \eqref{ref11}:</p>
                            $$
                            \begin{equation}
                            \frac{\partial L}{\partial W} = \begin{bmatrix}
                            (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \times x_1 \\
                            (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \times x_2 \\
                            (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \times x_3 \\
                            \end{bmatrix}
                            \label{ref18} \tag{18}
                            \end{equation}
                            $$
                            $$
                            \begin{equation}
                            = \begin{bmatrix}
                            x^1 \\
                            x^2 \\
                            x^3 \\
                            \end{bmatrix}
                            * [(\hat{y} - y) \times \hat{y} \times (1 - \hat{y})]
                            \label{ref19} \tag{19}
                            \end{equation}
                            $$
                            <p>Let \( \Delta l_{1} = (\hat{y} - y) \times \hat{y} \times (1 - \hat{y}) \).</p>
                            <p>Using \( \eqref{ref20} \) in \( \eqref{ref19} \), we get:</p>
                            $$
                            \begin{align}
                            \frac{\partial L}{\partial W} &= [X^{T}] . \Delta l_{1} \\
                            \end{align}
                            $$

                        </div>
                    </article>
                </div>

            </div>

            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients - Part 1</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Aug 26, 2014</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p><strong>Part 1 of computing gradients for training Neural Nets</strong></p>
                            <p><strong>1 layer network, 1 training example (scalar)</strong></p>
                            <p>
                                Consider a simplest version of a neural net - 1 layer, 1 input node (scalar)

                            </p>
                            <p class="center two-thirds"><a href="/images/NN_1_1.jpeg"><img
                                        src="/images/NN_1_1.jpeg"></a></p>


                            <p>Input is (x,y): x, y both are scalars. (Later on everything will be a matrix, so just to
                                be using the same notation. We will abuse the notation to express scalars as matrices of
                                dimension \(1 \times 1\)). Thus, in matrix form x, y are
                                \[ [X]_{\scriptscriptstyle 1\times 1} \] and \[ [y]_{\scriptscriptstyle 1\times 1} \].
                                Let \(W\) be the weight matrix. In this case, it's
                                \[ [W]_{\scriptscriptstyle 1\times 1} \].</p>


                            <p>Let \( \hat{y} \) be the predicted output. Then,</p>
                            \[ \hat{y} = \sigma (Wx) = \frac{1}{1 + e^{-[X] \cdot [W]}} \label{ref0} \tag{0} \]

                            <p>Let loss be squared error loss. For ease of math, we take \( \frac{1}{2} \) of it.</p>
                            \[ L = \frac{1}{2} (y - \hat{y})^{2} \]

                            <p>Let's compute gradients,</p>
                            \[ \nabla_{W} L = \frac{\partial L}{\partial W} \]


                            <div>
                                <p> \[ \frac{\partial L}{\partial W} = \frac{\partial L}{\partial \hat{y}} \times
                                    \frac{\partial \hat{y}}{\partial W} \label{ref1} \tag{1} \] </p>
                                <p> \[ \frac{\partial L}{\partial \hat{y}} = \frac{1}{2} \times 2 \times (y -
                                    \hat{y})^{1} \times (-1) \label{ref2} \tag{2} \] </p>
                                <p> \[ \frac{\partial \hat{y}}{\partial W} = \left( \frac{1}{1 + e^{-[X] \cdot [W]}}
                                    \right) \times \left(1- \frac{1}{1 + e^{-[X] \cdot [W]}} \right) * X \dots
                                    \text{using [Eq C, Part-0]} \label{ref3} \tag{3} \] </p>
                                <p> \[ = \sigma (Wx) \times (1- \sigma (Wx)) * X \dots \text{using \(\eqref{ref0}\)} \]
                                </p>
                                <p> \[ = \hat{y} \times (1 - \hat{y}) * X \dots \text{using \(\eqref{ref0}\)}
                                    \label{ref33} \] </p>
                            </div>

                            <div>
                                <p> Substituting \(\eqref{ref2}\) & \(\eqref{ref3}\) in \(\eqref{ref1}\), we get </p>
                                <p> \[ \frac{\partial L}{\partial W} = \left( (-1) \times (y - \hat{y}) \right) \times
                                    \left( \hat{y} \times (1- \hat{y}) \times x \right) \] </p>
                                <p> \[ = -(y - \hat{y}) \times \hat{y} \times (1- \hat{y}) \times x \] </p>
                                <p> \[ = (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \times x \label{ref4} \tag{4}
                                    \] </p>
                            </div>

                            <div>
                                <p> Let, </p>
                                <p> \[ \Delta l_{1} = (\hat{y} - y) \times \hat{y} \times (1- \hat{y}) \label{ref5}
                                    \tag{5} \] </p>
                                <p> Then, eq \(\eqref{ref4}\) reduces to: </p>
                                <p> \[ \frac{\partial L}{\partial W} = \Delta l_{1} \times x \] </p>
                                <p> \[ = \Delta l_{1} * X \] </p>
                                <p> \[ = [X^{T}] . \Delta l_{1} \label{ref6} \tag{6} \] </p>
                            </div>




                        </div>
                    </article>
                </div>

            </div>
            <div class="list__item">
                <div class="blog-post-card small " onclick="expandCard(this)">
                    <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
                        <h2 class="archive__item-title" itemprop="headline" style="margin-top: 5px;">
                            <a>Gradients for Neural Nets</a>
                        </h2>
                        <!-- <p class="page__meta">
                        <i class="fa fa-clock-o" aria-hidden="true"></i>
                        less than 1 minute read
                    </p> -->
                        <p class="page__date">
                            <strong>
                                <i class="fa fa-fw fa-calendar" aria-hidden="true"></i>
                                Published:
                            </strong>
                            <time datetime="2013-08-14T00:00:00-07:00">Aug 08, 2014</time>
                        </p>
                        <p class="archive__item-excerpt" itemprop="description">
                        <div class="archive__item-excerpt">
                            <p>Training neural nets is all about <a
                                    href="http://deeplearning.stanford.edu/wiki/index.php/Deriving_gradients_using_the_backpropagation_idea">
                                    computin gradients </a> In case you are new to this idea, refer to this awesome
                                <a href="http://karpathy.github.io/neuralnets/">post</a> by Andrej Karpathy.
                                Briefly,
                                deep down
                                every
                                ML problem is an optimization problem. We want to "learn" (find) the weights which
                                will
                                result in least average loss. The way we do it is - start with arbitrary wieghts and
                                keep
                                adjusting them in small quantities until we get them right i.e. arrive at a set of
                                values
                                for which loss function has least value. Gradients tells us by how much should we
                                adjust
                                each of the weights.

                            </p>


                            <p>Not clear - check this
                                <li>
                                    <a href="https://www.youtube.com/watch?v=yFPLyDwVifc">Video by Andrew NG</a>
                                </li>
                                <li>
                                    <a href="http://www.offconvex.org/2016/12/20/backprop/"> Blog by Sanjeev
                                        Arora</a>
                                </li>

                            </p>


                            <div class="archive__item-excerpt">

                                <ul>
                                    <li>
                                        <p>
                                            In this post we will focus on the maths that goes into computing these
                                            gradients - we will systematically derive gradients. The complexity of
                                            calculations depends on 3 things:
                                        <ul>
                                            <li>Depth of the network</li>
                                            <li>
                                                Number of training examples (1 or more)</li>
                                            <li>
                                                Number of components in input (1=scalar, >1=vector)
                                            </li>
                                        </ul>
                                        </p>
                                        <p>

                                            Through out this post we assume:
                                        <ul>
                                            <li> There is no bias term.
                                            </li>
                                            <li>`.` is matrix multiplication, `*` is element wise product and `X` is
                                                normal multiplication.</li>

                                            <li>
                                                All activations are <strong><a
                                                        href="https://www.quora.com/What-is-the-sigmoid-function-and-what-is-its-use-in-machine-learnings-neural-networks">sigmoid
                                                        a.k.a logistic</a></strong>. It is defined as \( f(u) =
                                                \frac{1}{1+e^{-u}} \). If you plot it, it comes as:.
                                            </li>
                                        </ul>

                                        </p>
                                        <p class="center two-thirds"><a href="/images/logistic.png"><img
                                                    src="/images/logistic.png"></a></p>


                                    </li>
                                    <p> <strong>Sigmoid function</strong> </p>
                                    <p>
                                        It easy to see it is smooth and differentiable and bound between 0 and 1 [No?
                                        not straight forward - need to fix this]. </p>
                                    <p>

                                        \[
                                        \begin{align}
                                        \frac{d}{dx}\sigma(x) &= \frac{d}{dx} \left[ \frac{1}{1+e^{-x}}\right]
                                        \label{refB} \tag{B}\\
                                        &= \frac{d}{dx} (1+e^{-x})^{-1} \\
                                        &= -(1+e^{-x})^{-2}(-e^{-x}) \\
                                        &= \frac{e^{-x}}{(1+e^{-x})^2} \\
                                        &= \frac{1}{(1+e^{-x})} \cdot \frac{e^{-x}}{(1+e^{-x})} \\
                                        &= \frac{1}{(1+e^{-x})} \cdot \frac{1 + e^{-x} -1}{(1+e^{-x})} \\
                                        &= \frac{1}{(1+e^{-x})} \cdot \left( 1 - \frac{e^{-x}}{(1+e^{-x})} \right) \\
                                        &= \sigma(x)(1-\sigma(x)) \label{refC} \tag{C}
                                        \end{align}
                                        \]

                                        <!-- Equation (D) -->
                                        \[
                                        \begin{align}
                                        \frac{d}{dx}\sigma(ax) = a(\sigma(ax))(1-\sigma(ax)) \label{refD} \tag{D}
                                        \end{align}
                                        \]

                                    </p>


                                </ul>
                            </div>

                            <div class="archive__item-excerpt">
                                <p> We will be using the above result a lot, so make sure you understand it. If it is
                                    not
                                    clear, have a look at this<strong> <a
                                            href="http://kawahara.ca/how-to-compute-the-derivative-of-a-sigmoid-function-fully-worked-example/">post
                                            .</a></strong>
                                </p>
                                <p>
                                <ul>To compute the gradients, we will start with the simplest case and increase the

                                    complexity gradually. To keep things simple we will complete it in 7 parts
                                    <li type="number">
                                        1 layer network, 1 training example
                                        (scalar).
                                    </li>
                                    <li> 1 layer network, 1 training example
                                        (vector)</li>
                                    <li>1 layer network, batch training (>1 training examples where each is a
                                        vector)</li>
                                    <li>2 layer network with 1 node hidden layer, 1 training example
                                        (vector </li>
                                    <li>2 layer network with 2 node hidden layer, 1 training example
                                        (vector)</li>
                                    <li>2 layer network, batch training (>1 training examples where each is a vector)
                                    </li>
                                    <li>Generalization and take home</li>
                                </ul>
                                <p> Since we will be dealing with matrices, a key step in every equation is to check if
                                    all matrix dimensions are consistent.</p>

                                </p>




                            </div>
                        </div>
                    </article>
                </div>

            </div>

        </div>
    </div>
    <div class="page__footer">
        <footer>
            <!-- start custom footer snippets -->
            <a>I’m always excited to meet new people. let’s connect and see where it takes us!</a>
            <!-- end custom footer snippets -->
            <div class="page__footer-follow">
                <ul class="social-icons">
                    <li>
                        <strong>STAY CONNECTED</strong>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/anujgupta-82/">
                            <i class="fa-brands fa-linkedin"></i>
                            LinkedIn
                        </a>
                    </li>
                    <li>
                        <a href="https://twitter.com/anujgupta82">
                            <i class="fa fa-twitter"></i>
                            Twitter
                        </a>
                    </li>
                    <li>
                        <a href="https://gradient-advisors.ai/">
                            <i class="fa-solid fa-globe" aria-hidden="true"></i> Gradient Advisors
                        </a>
                    </li>
                </ul>
            </div>
            <!-- <div class="page__footer-copyright">
                &copy;2019 Your Name. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a>
                &amp;<a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>
                , a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/"
                    rel="nofollow">Minimal Mistakes</a>
                .
            </div> -->
        </footer>
    </div>
    <!-- <script src="https://academicpages.github.io/assets/js/main.min.js"></script> -->
    <script src="/data/main.js"></script>


</body>

</html>